[2021-12-20 16:59:22.161783 UTC] Starting env pool
[2021-12-20 16:59:22.214041 UTC] Starting iteration 0
[2021-12-20 16:59:22.214507 UTC] Start collecting samples
[2021-12-20 16:59:23.565847 UTC] Computing input variables for policy optimization
[2021-12-20 16:59:23.642113 UTC] Performing policy update
[2021-12-20 16:59:23.649610 UTC] Computing gradient in Euclidean space
[2021-12-20 16:59:23.736819 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 16:59:24.341237 UTC] Performing line search
[2021-12-20 16:59:24.381405 UTC] Updating baseline
[2021-12-20 16:59:25.181985 UTC] Computing logging information
-------------------------------------
| Iteration            | 0          |
| ExpectedImprovement  | 0.0060539  |
| ActualImprovement    | 0.0047494  |
| ImprovementRatio     | 0.78452    |
| MeanKL               | 0.008382   |
| Entropy              | 1.4189     |
| Perplexity           | 4.1327     |
| AveragePolicyStd     | 1          |
| AveragePolicyStd[0]  | 1          |
| AverageReturn        | -1125.4    |
| MinReturn            | -1816      |
| MaxReturn            | -842.99    |
| StdReturn            | 189.13     |
| AverageEpisodeLength | 200        |
| MinEpisodeLength     | 200        |
| MaxEpisodeLength     | 200        |
| StdEpisodeLength     | 0          |
| TotalNEpisodes       | 48         |
| TotalNSamples        | 9600       |
| ExplainedVariance    | -0.0010832 |
-------------------------------------
[2021-12-20 16:59:25.248692 UTC] Saving snapshot
[2021-12-20 16:59:25.269542 UTC] Starting iteration 1
[2021-12-20 16:59:25.270249 UTC] Start collecting samples
[2021-12-20 16:59:29.303160 UTC] Computing input variables for policy optimization
[2021-12-20 16:59:29.358985 UTC] Performing policy update
[2021-12-20 16:59:29.359595 UTC] Computing gradient in Euclidean space
[2021-12-20 16:59:29.399538 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 16:59:29.993092 UTC] Performing line search
[2021-12-20 16:59:30.068453 UTC] Updating baseline
[2021-12-20 16:59:30.849605 UTC] Computing logging information
------------------------------------
| Iteration            | 1         |
| ExpectedImprovement  | 0.0042242 |
| ActualImprovement    | 0.0050502 |
| ImprovementRatio     | 1.1955    |
| MeanKL               | 0.0070182 |
| Entropy              | 1.4205    |
| Perplexity           | 4.1394    |
| AveragePolicyStd     | 1.0016    |
| AveragePolicyStd[0]  | 1.0016    |
| AverageReturn        | -1159.1   |
| MinReturn            | -1816     |
| MaxReturn            | -842.99   |
| StdReturn            | 186.69    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 96        |
| TotalNSamples        | 19200     |
| ExplainedVariance    | 0.09668   |
------------------------------------
[2021-12-20 16:59:30.937604 UTC] Saving snapshot
[2021-12-20 16:59:30.947425 UTC] Starting iteration 2
[2021-12-20 16:59:30.947717 UTC] Start collecting samples
[2021-12-20 16:59:32.526690 UTC] Computing input variables for policy optimization
[2021-12-20 16:59:32.606242 UTC] Performing policy update
[2021-12-20 16:59:32.607809 UTC] Computing gradient in Euclidean space
[2021-12-20 16:59:32.665811 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 16:59:33.288591 UTC] Performing line search
[2021-12-20 16:59:33.374222 UTC] Updating baseline
[2021-12-20 16:59:34.067405 UTC] Computing logging information
------------------------------------
| Iteration            | 2         |
| ExpectedImprovement  | 0.005404  |
| ActualImprovement    | 0.0059291 |
| ImprovementRatio     | 1.0972    |
| MeanKL               | 0.0070118 |
| Entropy              | 1.4146    |
| Perplexity           | 4.115     |
| AveragePolicyStd     | 0.99571   |
| AveragePolicyStd[0]  | 0.99571   |
| AverageReturn        | -1159.1   |
| MinReturn            | -1625.1   |
| MaxReturn            | -865.54   |
| StdReturn            | 179.19    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 144       |
| TotalNSamples        | 28800     |
| ExplainedVariance    | 0.17805   |
------------------------------------
[2021-12-20 16:59:34.117231 UTC] Saving snapshot
[2021-12-20 16:59:34.121194 UTC] Starting iteration 3
[2021-12-20 16:59:34.121562 UTC] Start collecting samples
[2021-12-20 16:59:35.888272 UTC] Computing input variables for policy optimization
[2021-12-20 16:59:36.023727 UTC] Performing policy update
[2021-12-20 16:59:36.030966 UTC] Computing gradient in Euclidean space
[2021-12-20 16:59:36.079024 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 16:59:36.889738 UTC] Performing line search
[2021-12-20 16:59:36.978953 UTC] Updating baseline
[2021-12-20 16:59:37.783007 UTC] Computing logging information
------------------------------------
| Iteration            | 3         |
| ExpectedImprovement  | 0.0043774 |
| ActualImprovement    | 0.0041566 |
| ImprovementRatio     | 0.94956   |
| MeanKL               | 0.0070574 |
| Entropy              | 1.4405    |
| Perplexity           | 4.2229    |
| AveragePolicyStd     | 1.0218    |
| AveragePolicyStd[0]  | 1.0218    |
| AverageReturn        | -1139.2   |
| MinReturn            | -1641.9   |
| MaxReturn            | -787.54   |
| StdReturn            | 205.37    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 192       |
| TotalNSamples        | 38400     |
| ExplainedVariance    | 0.29958   |
------------------------------------
[2021-12-20 16:59:37.851219 UTC] Saving snapshot
[2021-12-20 16:59:37.858538 UTC] Starting iteration 4
[2021-12-20 16:59:37.858781 UTC] Start collecting samples
[2021-12-20 16:59:39.863263 UTC] Computing input variables for policy optimization
[2021-12-20 16:59:39.947369 UTC] Performing policy update
[2021-12-20 16:59:39.948227 UTC] Computing gradient in Euclidean space
[2021-12-20 16:59:40.001283 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 16:59:40.566736 UTC] Performing line search
[2021-12-20 16:59:40.627254 UTC] Updating baseline
[2021-12-20 16:59:41.497741 UTC] Computing logging information
------------------------------------
| Iteration            | 4         |
| ExpectedImprovement  | 0.004951  |
| ActualImprovement    | 0.005006  |
| ImprovementRatio     | 1.0111    |
| MeanKL               | 0.0070568 |
| Entropy              | 1.4215    |
| Perplexity           | 4.1435    |
| AveragePolicyStd     | 1.0026    |
| AveragePolicyStd[0]  | 1.0026    |
| AverageReturn        | -1106.1   |
| MinReturn            | -1641.9   |
| MaxReturn            | -748      |
| StdReturn            | 210.67    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 240       |
| TotalNSamples        | 48000     |
| ExplainedVariance    | 0.41701   |
------------------------------------
[2021-12-20 16:59:41.611684 UTC] Saving snapshot
[2021-12-20 16:59:41.629264 UTC] Starting iteration 5
[2021-12-20 16:59:41.629617 UTC] Start collecting samples
[2021-12-20 16:59:44.779104 UTC] Computing input variables for policy optimization
[2021-12-20 16:59:44.859880 UTC] Performing policy update
[2021-12-20 16:59:44.860570 UTC] Computing gradient in Euclidean space
[2021-12-20 16:59:44.931575 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 16:59:45.695446 UTC] Performing line search
[2021-12-20 16:59:45.753987 UTC] Updating baseline
[2021-12-20 16:59:46.446391 UTC] Computing logging information
------------------------------------
| Iteration            | 5         |
| ExpectedImprovement  | 0.0052623 |
| ActualImprovement    | 0.0056203 |
| ImprovementRatio     | 1.068     |
| MeanKL               | 0.0069089 |
| Entropy              | 1.4275    |
| Perplexity           | 4.1683    |
| AveragePolicyStd     | 1.0086    |
| AveragePolicyStd[0]  | 1.0086    |
| AverageReturn        | -1056.4   |
| MinReturn            | -1469.1   |
| MaxReturn            | -748      |
| StdReturn            | 186.55    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 288       |
| TotalNSamples        | 57600     |
| ExplainedVariance    | 0.52452   |
------------------------------------
[2021-12-20 16:59:46.515399 UTC] Saving snapshot
[2021-12-20 16:59:46.522808 UTC] Starting iteration 6
[2021-12-20 16:59:46.523198 UTC] Start collecting samples
[2021-12-20 16:59:49.323931 UTC] Computing input variables for policy optimization
[2021-12-20 16:59:49.450811 UTC] Performing policy update
[2021-12-20 16:59:49.453242 UTC] Computing gradient in Euclidean space
[2021-12-20 16:59:49.549794 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 16:59:50.318236 UTC] Performing line search
[2021-12-20 16:59:50.365584 UTC] Updating baseline
[2021-12-20 16:59:51.348135 UTC] Computing logging information
------------------------------------
| Iteration            | 6         |
| ExpectedImprovement  | 0.007042  |
| ActualImprovement    | 0.0065468 |
| ImprovementRatio     | 0.92967   |
| MeanKL               | 0.0094    |
| Entropy              | 1.4388    |
| Perplexity           | 4.2158    |
| AveragePolicyStd     | 1.0201    |
| AveragePolicyStd[0]  | 1.0201    |
| AverageReturn        | -1072.7   |
| MinReturn            | -1501.9   |
| MaxReturn            | -762.29   |
| StdReturn            | 188.2     |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 336       |
| TotalNSamples        | 67200     |
| ExplainedVariance    | 0.52615   |
------------------------------------
[2021-12-20 16:59:51.415665 UTC] Saving snapshot
[2021-12-20 16:59:51.423039 UTC] Starting iteration 7
[2021-12-20 16:59:51.423558 UTC] Start collecting samples
[2021-12-20 16:59:54.694714 UTC] Computing input variables for policy optimization
[2021-12-20 16:59:54.752722 UTC] Performing policy update
[2021-12-20 16:59:54.754981 UTC] Computing gradient in Euclidean space
[2021-12-20 16:59:54.802652 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 16:59:55.634368 UTC] Performing line search
[2021-12-20 16:59:55.760831 UTC] Updating baseline
[2021-12-20 16:59:56.535529 UTC] Computing logging information
------------------------------------
| Iteration            | 7         |
| ExpectedImprovement  | 0.0081169 |
| ActualImprovement    | 0.0077225 |
| ImprovementRatio     | 0.95141   |
| MeanKL               | 0.0071461 |
| Entropy              | 1.4509    |
| Perplexity           | 4.2671    |
| AveragePolicyStd     | 1.0325    |
| AveragePolicyStd[0]  | 1.0325    |
| AverageReturn        | -1028.2   |
| MinReturn            | -1501.9   |
| MaxReturn            | -746.98   |
| StdReturn            | 170.91    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 400       |
| TotalNSamples        | 80000     |
| ExplainedVariance    | 0.67208   |
------------------------------------
[2021-12-20 16:59:56.599285 UTC] Saving snapshot
[2021-12-20 16:59:56.607227 UTC] Starting iteration 8
[2021-12-20 16:59:56.607751 UTC] Start collecting samples
[2021-12-20 16:59:58.852915 UTC] Computing input variables for policy optimization
[2021-12-20 16:59:58.946801 UTC] Performing policy update
[2021-12-20 16:59:58.952692 UTC] Computing gradient in Euclidean space
[2021-12-20 16:59:59.019501 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 16:59:59.770550 UTC] Performing line search
[2021-12-20 16:59:59.810330 UTC] Updating baseline
[2021-12-20 17:00:00.877192 UTC] Computing logging information
------------------------------------
| Iteration            | 8         |
| ExpectedImprovement  | 0.009332  |
| ActualImprovement    | 0.0088187 |
| ImprovementRatio     | 0.945     |
| MeanKL               | 0.0090481 |
| Entropy              | 1.4468    |
| Perplexity           | 4.2494    |
| AveragePolicyStd     | 1.0282    |
| AveragePolicyStd[0]  | 1.0282    |
| AverageReturn        | -990.49   |
| MinReturn            | -1428.9   |
| MaxReturn            | -744.21   |
| StdReturn            | 160.83    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 448       |
| TotalNSamples        | 89600     |
| ExplainedVariance    | 0.85982   |
------------------------------------
[2021-12-20 17:00:00.936447 UTC] Saving snapshot
[2021-12-20 17:00:00.942377 UTC] Starting iteration 9
[2021-12-20 17:00:00.942643 UTC] Start collecting samples
[2021-12-20 17:00:02.729210 UTC] Computing input variables for policy optimization
[2021-12-20 17:00:02.783191 UTC] Performing policy update
[2021-12-20 17:00:02.784164 UTC] Computing gradient in Euclidean space
[2021-12-20 17:00:02.840818 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:00:03.472471 UTC] Performing line search
[2021-12-20 17:00:03.592979 UTC] Updating baseline
[2021-12-20 17:00:04.599321 UTC] Computing logging information
------------------------------------
| Iteration            | 9         |
| ExpectedImprovement  | 0.0073399 |
| ActualImprovement    | 0.0075228 |
| ImprovementRatio     | 1.0249    |
| MeanKL               | 0.0090901 |
| Entropy              | 1.456     |
| Perplexity           | 4.2887    |
| AveragePolicyStd     | 1.0377    |
| AveragePolicyStd[0]  | 1.0377    |
| AverageReturn        | -969.13   |
| MinReturn            | -1428.9   |
| MaxReturn            | -701.83   |
| StdReturn            | 156.77    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 496       |
| TotalNSamples        | 99200     |
| ExplainedVariance    | 0.86493   |
------------------------------------
[2021-12-20 17:00:04.655115 UTC] Saving snapshot
[2021-12-20 17:00:04.660191 UTC] Starting iteration 10
[2021-12-20 17:00:04.660467 UTC] Start collecting samples
[2021-12-20 17:00:09.187572 UTC] Computing input variables for policy optimization
[2021-12-20 17:00:09.241008 UTC] Performing policy update
[2021-12-20 17:00:09.241707 UTC] Computing gradient in Euclidean space
[2021-12-20 17:00:09.327625 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:00:09.966310 UTC] Performing line search
[2021-12-20 17:00:09.997999 UTC] Updating baseline
[2021-12-20 17:00:10.603652 UTC] Computing logging information
------------------------------------
| Iteration            | 10        |
| ExpectedImprovement  | 0.01019   |
| ActualImprovement    | 0.0086539 |
| ImprovementRatio     | 0.84928   |
| MeanKL               | 0.0091063 |
| Entropy              | 1.4833    |
| Perplexity           | 4.4075    |
| AveragePolicyStd     | 1.0665    |
| AveragePolicyStd[0]  | 1.0665    |
| AverageReturn        | -902.95   |
| MinReturn            | -1316.1   |
| MaxReturn            | -623.94   |
| StdReturn            | 149.52    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 544       |
| TotalNSamples        | 1.088e+05 |
| ExplainedVariance    | 0.81045   |
------------------------------------
[2021-12-20 17:00:10.778589 UTC] Saving snapshot
[2021-12-20 17:00:10.869992 UTC] Starting iteration 11
[2021-12-20 17:00:10.870595 UTC] Start collecting samples
[2021-12-20 17:00:13.151835 UTC] Computing input variables for policy optimization
[2021-12-20 17:00:13.233526 UTC] Performing policy update
[2021-12-20 17:00:13.234733 UTC] Computing gradient in Euclidean space
[2021-12-20 17:00:13.293386 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:00:13.899787 UTC] Performing line search
[2021-12-20 17:00:13.984247 UTC] Updating baseline
[2021-12-20 17:00:14.802576 UTC] Computing logging information
------------------------------------
| Iteration            | 11        |
| ExpectedImprovement  | 0.0083328 |
| ActualImprovement    | 0.0086806 |
| ImprovementRatio     | 1.0417    |
| MeanKL               | 0.0072776 |
| Entropy              | 1.4506    |
| Perplexity           | 4.2656    |
| AveragePolicyStd     | 1.0321    |
| AveragePolicyStd[0]  | 1.0321    |
| AverageReturn        | -864.06   |
| MinReturn            | -1316.1   |
| MaxReturn            | -622.09   |
| StdReturn            | 148.02    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 592       |
| TotalNSamples        | 1.184e+05 |
| ExplainedVariance    | 0.75498   |
------------------------------------
[2021-12-20 17:00:14.881637 UTC] Saving snapshot
[2021-12-20 17:00:14.887413 UTC] Starting iteration 12
[2021-12-20 17:00:14.887847 UTC] Start collecting samples
[2021-12-20 17:00:16.997632 UTC] Computing input variables for policy optimization
[2021-12-20 17:00:17.102749 UTC] Performing policy update
[2021-12-20 17:00:17.104821 UTC] Computing gradient in Euclidean space
[2021-12-20 17:00:17.178225 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:00:17.865713 UTC] Performing line search
[2021-12-20 17:00:17.935599 UTC] Updating baseline
[2021-12-20 17:00:19.010594 UTC] Computing logging information
------------------------------------
| Iteration            | 12        |
| ExpectedImprovement  | 0.0059526 |
| ActualImprovement    | 0.0057862 |
| ImprovementRatio     | 0.97204   |
| MeanKL               | 0.0068546 |
| Entropy              | 1.4317    |
| Perplexity           | 4.1858    |
| AveragePolicyStd     | 1.0128    |
| AveragePolicyStd[0]  | 1.0128    |
| AverageReturn        | -853.48   |
| MinReturn            | -1195.2   |
| MaxReturn            | -619.68   |
| StdReturn            | 142.32    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 640       |
| TotalNSamples        | 1.28e+05  |
| ExplainedVariance    | 0.71015   |
------------------------------------
[2021-12-20 17:00:19.119452 UTC] Saving snapshot
[2021-12-20 17:00:19.125160 UTC] Starting iteration 13
[2021-12-20 17:00:19.125522 UTC] Start collecting samples
[2021-12-20 17:00:23.706728 UTC] Computing input variables for policy optimization
[2021-12-20 17:00:23.760176 UTC] Performing policy update
[2021-12-20 17:00:23.764619 UTC] Computing gradient in Euclidean space
[2021-12-20 17:00:23.816135 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:00:24.350494 UTC] Performing line search
[2021-12-20 17:00:24.409138 UTC] Updating baseline
[2021-12-20 17:00:25.128547 UTC] Computing logging information
------------------------------------
| Iteration            | 13        |
| ExpectedImprovement  | 0.0060166 |
| ActualImprovement    | 0.0059812 |
| ImprovementRatio     | 0.99412   |
| MeanKL               | 0.0064771 |
| Entropy              | 1.3993    |
| Perplexity           | 4.0522    |
| AveragePolicyStd     | 0.98052   |
| AveragePolicyStd[0]  | 0.98052   |
| AverageReturn        | -844.74   |
| MinReturn            | -1164.3   |
| MaxReturn            | -615.82   |
| StdReturn            | 145.97    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 688       |
| TotalNSamples        | 1.376e+05 |
| ExplainedVariance    | 0.70811   |
------------------------------------
[2021-12-20 17:00:25.195400 UTC] Saving snapshot
[2021-12-20 17:00:25.202179 UTC] Starting iteration 14
[2021-12-20 17:00:25.202566 UTC] Start collecting samples
[2021-12-20 17:00:26.909038 UTC] Computing input variables for policy optimization
[2021-12-20 17:00:26.993581 UTC] Performing policy update
[2021-12-20 17:00:26.997701 UTC] Computing gradient in Euclidean space
[2021-12-20 17:00:27.042672 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:00:27.657325 UTC] Performing line search
[2021-12-20 17:00:27.729993 UTC] Updating baseline
[2021-12-20 17:00:28.356428 UTC] Computing logging information
------------------------------------
| Iteration            | 14        |
| ExpectedImprovement  | 0.007132  |
| ActualImprovement    | 0.0071522 |
| ImprovementRatio     | 1.0028    |
| MeanKL               | 0.0068397 |
| Entropy              | 1.4003    |
| Perplexity           | 4.0563    |
| AveragePolicyStd     | 0.98151   |
| AveragePolicyStd[0]  | 0.98151   |
| AverageReturn        | -793.97   |
| MinReturn            | -1130.4   |
| MaxReturn            | -501.29   |
| StdReturn            | 136.14    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 736       |
| TotalNSamples        | 1.472e+05 |
| ExplainedVariance    | 0.67466   |
------------------------------------
[2021-12-20 17:00:28.405548 UTC] Saving snapshot
[2021-12-20 17:00:28.419540 UTC] Starting iteration 15
[2021-12-20 17:00:28.419731 UTC] Start collecting samples
[2021-12-20 17:00:29.925850 UTC] Computing input variables for policy optimization
[2021-12-20 17:00:29.983675 UTC] Performing policy update
[2021-12-20 17:00:29.985082 UTC] Computing gradient in Euclidean space
[2021-12-20 17:00:30.057050 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:00:30.705142 UTC] Performing line search
[2021-12-20 17:00:30.778580 UTC] Updating baseline
[2021-12-20 17:00:31.358966 UTC] Computing logging information
------------------------------------
| Iteration            | 15        |
| ExpectedImprovement  | 0.0060087 |
| ActualImprovement    | 0.0063804 |
| ImprovementRatio     | 1.0619    |
| MeanKL               | 0.0065351 |
| Entropy              | 1.378     |
| Perplexity           | 3.967     |
| AveragePolicyStd     | 0.95991   |
| AveragePolicyStd[0]  | 0.95991   |
| AverageReturn        | -752.39   |
| MinReturn            | -1082.5   |
| MaxReturn            | -492.53   |
| StdReturn            | 138.75    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 800       |
| TotalNSamples        | 1.6e+05   |
| ExplainedVariance    | 0.77537   |
------------------------------------
[2021-12-20 17:00:31.415291 UTC] Saving snapshot
[2021-12-20 17:00:31.419924 UTC] Starting iteration 16
[2021-12-20 17:00:31.420171 UTC] Start collecting samples
[2021-12-20 17:00:32.711246 UTC] Computing input variables for policy optimization
[2021-12-20 17:00:32.763781 UTC] Performing policy update
[2021-12-20 17:00:32.764657 UTC] Computing gradient in Euclidean space
[2021-12-20 17:00:32.830632 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:00:33.374632 UTC] Performing line search
[2021-12-20 17:00:33.446383 UTC] Updating baseline
[2021-12-20 17:00:34.043331 UTC] Computing logging information
------------------------------------
| Iteration            | 16        |
| ExpectedImprovement  | 0.0089613 |
| ActualImprovement    | 0.0086958 |
| ImprovementRatio     | 0.97037   |
| MeanKL               | 0.0067762 |
| Entropy              | 1.3795    |
| Perplexity           | 3.9727    |
| AveragePolicyStd     | 0.96128   |
| AveragePolicyStd[0]  | 0.96128   |
| AverageReturn        | -742.24   |
| MinReturn            | -1082.5   |
| MaxReturn            | -383.02   |
| StdReturn            | 144.5     |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 848       |
| TotalNSamples        | 1.696e+05 |
| ExplainedVariance    | 0.83752   |
------------------------------------
[2021-12-20 17:00:34.098278 UTC] Saving snapshot
[2021-12-20 17:00:34.101886 UTC] Starting iteration 17
[2021-12-20 17:00:34.102066 UTC] Start collecting samples
[2021-12-20 17:00:35.583162 UTC] Computing input variables for policy optimization
[2021-12-20 17:00:35.669872 UTC] Performing policy update
[2021-12-20 17:00:35.671233 UTC] Computing gradient in Euclidean space
[2021-12-20 17:00:35.744018 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:00:36.316878 UTC] Performing line search
[2021-12-20 17:00:36.345509 UTC] Updating baseline
[2021-12-20 17:00:36.915604 UTC] Computing logging information
------------------------------------
| Iteration            | 17        |
| ExpectedImprovement  | 0.010724  |
| ActualImprovement    | 0.01009   |
| ImprovementRatio     | 0.94087   |
| MeanKL               | 0.0097263 |
| Entropy              | 1.3564    |
| Perplexity           | 3.8821    |
| AveragePolicyStd     | 0.93936   |
| AveragePolicyStd[0]  | 0.93936   |
| AverageReturn        | -706.1    |
| MinReturn            | -1082.5   |
| MaxReturn            | -383.02   |
| StdReturn            | 141.95    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 896       |
| TotalNSamples        | 1.792e+05 |
| ExplainedVariance    | 0.85119   |
------------------------------------
[2021-12-20 17:00:36.971473 UTC] Saving snapshot
[2021-12-20 17:00:36.981830 UTC] Starting iteration 18
[2021-12-20 17:00:36.983396 UTC] Start collecting samples
[2021-12-20 17:00:38.489964 UTC] Computing input variables for policy optimization
[2021-12-20 17:00:38.543671 UTC] Performing policy update
[2021-12-20 17:00:38.548490 UTC] Computing gradient in Euclidean space
[2021-12-20 17:00:38.593411 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:00:39.120224 UTC] Performing line search
[2021-12-20 17:00:39.177043 UTC] Updating baseline
[2021-12-20 17:00:39.777628 UTC] Computing logging information
------------------------------------
| Iteration            | 18        |
| ExpectedImprovement  | 0.0091051 |
| ActualImprovement    | 0.0092853 |
| ImprovementRatio     | 1.0198    |
| MeanKL               | 0.0072913 |
| Entropy              | 1.3467    |
| Perplexity           | 3.8447    |
| AveragePolicyStd     | 0.93031   |
| AveragePolicyStd[0]  | 0.93031   |
| AverageReturn        | -648.33   |
| MinReturn            | -926.81   |
| MaxReturn            | -377.88   |
| StdReturn            | 135.09    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 944       |
| TotalNSamples        | 1.888e+05 |
| ExplainedVariance    | 0.78346   |
------------------------------------
[2021-12-20 17:00:39.836977 UTC] Saving snapshot
[2021-12-20 17:00:39.847878 UTC] Starting iteration 19
[2021-12-20 17:00:39.848032 UTC] Start collecting samples
[2021-12-20 17:00:41.418417 UTC] Computing input variables for policy optimization
[2021-12-20 17:00:41.481422 UTC] Performing policy update
[2021-12-20 17:00:41.484350 UTC] Computing gradient in Euclidean space
[2021-12-20 17:00:41.526815 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:00:42.072330 UTC] Performing line search
[2021-12-20 17:00:42.132586 UTC] Updating baseline
[2021-12-20 17:00:43.074285 UTC] Computing logging information
------------------------------------
| Iteration            | 19        |
| ExpectedImprovement  | 0.010928  |
| ActualImprovement    | 0.010737  |
| ImprovementRatio     | 0.98256   |
| MeanKL               | 0.0066064 |
| Entropy              | 1.3263    |
| Perplexity           | 3.767     |
| AveragePolicyStd     | 0.9115    |
| AveragePolicyStd[0]  | 0.9115    |
| AverageReturn        | -601.51   |
| MinReturn            | -916.13   |
| MaxReturn            | -280.02   |
| StdReturn            | 139.41    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 992       |
| TotalNSamples        | 1.984e+05 |
| ExplainedVariance    | 0.71985   |
------------------------------------
[2021-12-20 17:00:43.153805 UTC] Saving snapshot
[2021-12-20 17:00:43.158838 UTC] Starting iteration 20
[2021-12-20 17:00:43.159174 UTC] Start collecting samples
[2021-12-20 17:00:44.949438 UTC] Computing input variables for policy optimization
[2021-12-20 17:00:45.011988 UTC] Performing policy update
[2021-12-20 17:00:45.012665 UTC] Computing gradient in Euclidean space
[2021-12-20 17:00:45.082777 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:00:45.623803 UTC] Performing line search
[2021-12-20 17:00:45.667265 UTC] Updating baseline
[2021-12-20 17:00:46.320469 UTC] Computing logging information
------------------------------------
| Iteration            | 20        |
| ExpectedImprovement  | 0.011332  |
| ActualImprovement    | 0.01074   |
| ImprovementRatio     | 0.9478    |
| MeanKL               | 0.0093863 |
| Entropy              | 1.306     |
| Perplexity           | 3.6915    |
| AveragePolicyStd     | 0.89323   |
| AveragePolicyStd[0]  | 0.89323   |
| AverageReturn        | -575.12   |
| MinReturn            | -916.13   |
| MaxReturn            | -280.02   |
| StdReturn            | 138.68    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1040      |
| TotalNSamples        | 2.08e+05  |
| ExplainedVariance    | 0.76279   |
------------------------------------
[2021-12-20 17:00:46.410641 UTC] Saving snapshot
[2021-12-20 17:00:46.420838 UTC] Starting iteration 21
[2021-12-20 17:00:46.421452 UTC] Start collecting samples
[2021-12-20 17:00:48.108487 UTC] Computing input variables for policy optimization
[2021-12-20 17:00:48.176644 UTC] Performing policy update
[2021-12-20 17:00:48.182631 UTC] Computing gradient in Euclidean space
[2021-12-20 17:00:48.249426 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:00:48.836251 UTC] Performing line search
[2021-12-20 17:00:48.907012 UTC] Updating baseline
[2021-12-20 17:00:49.463699 UTC] Computing logging information
------------------------------------
| Iteration            | 21        |
| ExpectedImprovement  | 0.012066  |
| ActualImprovement    | 0.011524  |
| ImprovementRatio     | 0.9551    |
| MeanKL               | 0.0068048 |
| Entropy              | 1.3049    |
| Perplexity           | 3.6873    |
| AveragePolicyStd     | 0.89221   |
| AveragePolicyStd[0]  | 0.89221   |
| AverageReturn        | -546.25   |
| MinReturn            | -912.76   |
| MaxReturn            | -348.65   |
| StdReturn            | 126.9     |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1088      |
| TotalNSamples        | 2.176e+05 |
| ExplainedVariance    | 0.75191   |
------------------------------------
[2021-12-20 17:00:49.517794 UTC] Saving snapshot
[2021-12-20 17:00:49.527793 UTC] Starting iteration 22
[2021-12-20 17:00:49.530727 UTC] Start collecting samples
[2021-12-20 17:00:51.140023 UTC] Computing input variables for policy optimization
[2021-12-20 17:00:51.202540 UTC] Performing policy update
[2021-12-20 17:00:51.206608 UTC] Computing gradient in Euclidean space
[2021-12-20 17:00:51.248052 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:00:51.791141 UTC] Performing line search
[2021-12-20 17:00:51.874757 UTC] Updating baseline
[2021-12-20 17:00:52.553277 UTC] Computing logging information
------------------------------------
| Iteration            | 22        |
| ExpectedImprovement  | 0.013575  |
| ActualImprovement    | 0.01333   |
| ImprovementRatio     | 0.98199   |
| MeanKL               | 0.0066823 |
| Entropy              | 1.2682    |
| Perplexity           | 3.5543    |
| AveragePolicyStd     | 0.86005   |
| AveragePolicyStd[0]  | 0.86005   |
| AverageReturn        | -488.64   |
| MinReturn            | -812.87   |
| MaxReturn            | -244.97   |
| StdReturn            | 128.5     |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1136      |
| TotalNSamples        | 2.272e+05 |
| ExplainedVariance    | 0.79371   |
------------------------------------
[2021-12-20 17:00:52.623960 UTC] Saving snapshot
[2021-12-20 17:00:52.639320 UTC] Starting iteration 23
[2021-12-20 17:00:52.642954 UTC] Start collecting samples
[2021-12-20 17:00:54.349053 UTC] Computing input variables for policy optimization
[2021-12-20 17:00:54.406564 UTC] Performing policy update
[2021-12-20 17:00:54.415336 UTC] Computing gradient in Euclidean space
[2021-12-20 17:00:54.473153 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:00:55.056738 UTC] Performing line search
[2021-12-20 17:00:55.147214 UTC] Updating baseline
[2021-12-20 17:00:55.786881 UTC] Computing logging information
-----------------------------------
| Iteration            | 23       |
| ExpectedImprovement  | 0.013953 |
| ActualImprovement    | 0.013863 |
| ImprovementRatio     | 0.99357  |
| MeanKL               | 0.006818 |
| Entropy              | 1.2565   |
| Perplexity           | 3.5132   |
| AveragePolicyStd     | 0.85009  |
| AveragePolicyStd[0]  | 0.85009  |
| AverageReturn        | -425.81  |
| MinReturn            | -812.87  |
| MaxReturn            | -26.241  |
| StdReturn            | 152.08   |
| AverageEpisodeLength | 200      |
| MinEpisodeLength     | 200      |
| MaxEpisodeLength     | 200      |
| StdEpisodeLength     | 0        |
| TotalNEpisodes       | 1200     |
| TotalNSamples        | 2.4e+05  |
| ExplainedVariance    | 0.79705  |
-----------------------------------
[2021-12-20 17:00:55.858482 UTC] Saving snapshot
[2021-12-20 17:00:55.869198 UTC] Starting iteration 24
[2021-12-20 17:00:55.871013 UTC] Start collecting samples
[2021-12-20 17:00:57.572113 UTC] Computing input variables for policy optimization
[2021-12-20 17:00:57.636586 UTC] Performing policy update
[2021-12-20 17:00:57.637243 UTC] Computing gradient in Euclidean space
[2021-12-20 17:00:57.702430 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:00:58.314813 UTC] Performing line search
[2021-12-20 17:00:58.347583 UTC] Updating baseline
[2021-12-20 17:00:59.103549 UTC] Computing logging information
------------------------------------
| Iteration            | 24        |
| ExpectedImprovement  | 0.024306  |
| ActualImprovement    | 0.022356  |
| ImprovementRatio     | 0.91979   |
| MeanKL               | 0.0097739 |
| Entropy              | 1.2449    |
| Perplexity           | 3.4725    |
| AveragePolicyStd     | 0.84023   |
| AveragePolicyStd[0]  | 0.84023   |
| AverageReturn        | -343.85   |
| MinReturn            | -718.75   |
| MaxReturn            | -1.65     |
| StdReturn            | 162.78    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1248      |
| TotalNSamples        | 2.496e+05 |
| ExplainedVariance    | 0.8937    |
------------------------------------
[2021-12-20 17:00:59.172836 UTC] Saving snapshot
[2021-12-20 17:00:59.185069 UTC] Starting iteration 25
[2021-12-20 17:00:59.185267 UTC] Start collecting samples
[2021-12-20 17:01:00.654586 UTC] Computing input variables for policy optimization
[2021-12-20 17:01:00.717345 UTC] Performing policy update
[2021-12-20 17:01:00.721024 UTC] Computing gradient in Euclidean space
[2021-12-20 17:01:00.770615 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:01:01.358428 UTC] Performing line search
[2021-12-20 17:01:01.393381 UTC] Updating baseline
[2021-12-20 17:01:01.916349 UTC] Computing logging information
------------------------------------
| Iteration            | 25        |
| ExpectedImprovement  | 0.020315  |
| ActualImprovement    | 0.017799  |
| ImprovementRatio     | 0.87614   |
| MeanKL               | 0.0086224 |
| Entropy              | 1.2188    |
| Perplexity           | 3.3832    |
| AveragePolicyStd     | 0.81863   |
| AveragePolicyStd[0]  | 0.81863   |
| AverageReturn        | -271.88   |
| MinReturn            | -665.5    |
| MaxReturn            | -1.363    |
| StdReturn            | 157.14    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1296      |
| TotalNSamples        | 2.592e+05 |
| ExplainedVariance    | 0.88657   |
------------------------------------
[2021-12-20 17:01:01.986816 UTC] Saving snapshot
[2021-12-20 17:01:02.000017 UTC] Starting iteration 26
[2021-12-20 17:01:02.000756 UTC] Start collecting samples
[2021-12-20 17:01:03.790253 UTC] Computing input variables for policy optimization
[2021-12-20 17:01:03.864501 UTC] Performing policy update
[2021-12-20 17:01:03.868204 UTC] Computing gradient in Euclidean space
[2021-12-20 17:01:03.917726 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:01:04.489235 UTC] Performing line search
[2021-12-20 17:01:04.523452 UTC] Updating baseline
[2021-12-20 17:01:05.235145 UTC] Computing logging information
------------------------------------
| Iteration            | 26        |
| ExpectedImprovement  | 0.022657  |
| ActualImprovement    | 0.021707  |
| ImprovementRatio     | 0.95807   |
| MeanKL               | 0.0095262 |
| Entropy              | 1.2029    |
| Perplexity           | 3.3298    |
| AveragePolicyStd     | 0.80571   |
| AveragePolicyStd[0]  | 0.80571   |
| AverageReturn        | -238.85   |
| MinReturn            | -613.02   |
| MaxReturn            | -1.2196   |
| StdReturn            | 151.78    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1344      |
| TotalNSamples        | 2.688e+05 |
| ExplainedVariance    | 0.94852   |
------------------------------------
[2021-12-20 17:01:05.300881 UTC] Saving snapshot
[2021-12-20 17:01:05.307498 UTC] Starting iteration 27
[2021-12-20 17:01:05.312693 UTC] Start collecting samples
[2021-12-20 17:01:06.753119 UTC] Computing input variables for policy optimization
[2021-12-20 17:01:06.822272 UTC] Performing policy update
[2021-12-20 17:01:06.827935 UTC] Computing gradient in Euclidean space
[2021-12-20 17:01:06.871692 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:01:07.357194 UTC] Performing line search
[2021-12-20 17:01:07.384294 UTC] Updating baseline
[2021-12-20 17:01:08.004082 UTC] Computing logging information
------------------------------------
| Iteration            | 27        |
| ExpectedImprovement  | 0.012944  |
| ActualImprovement    | 0.010114  |
| ImprovementRatio     | 0.78142   |
| MeanKL               | 0.0091814 |
| Entropy              | 1.1896    |
| Perplexity           | 3.2857    |
| AveragePolicyStd     | 0.79504   |
| AveragePolicyStd[0]  | 0.79504   |
| AverageReturn        | -208      |
| MinReturn            | -592.16   |
| MaxReturn            | -1.2196   |
| StdReturn            | 150.16    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1392      |
| TotalNSamples        | 2.784e+05 |
| ExplainedVariance    | 0.93112   |
------------------------------------
[2021-12-20 17:01:08.100324 UTC] Saving snapshot
[2021-12-20 17:01:08.108882 UTC] Starting iteration 28
[2021-12-20 17:01:08.109672 UTC] Start collecting samples
[2021-12-20 17:01:09.746488 UTC] Computing input variables for policy optimization
[2021-12-20 17:01:09.814062 UTC] Performing policy update
[2021-12-20 17:01:09.817324 UTC] Computing gradient in Euclidean space
[2021-12-20 17:01:09.868477 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:01:10.447103 UTC] Performing line search
[2021-12-20 17:01:10.512390 UTC] Updating baseline
[2021-12-20 17:01:11.125873 UTC] Computing logging information
------------------------------------
| Iteration            | 28        |
| ExpectedImprovement  | 0.012596  |
| ActualImprovement    | 0.010894  |
| ImprovementRatio     | 0.86482   |
| MeanKL               | 0.0064583 |
| Entropy              | 1.1576    |
| Perplexity           | 3.1822    |
| AveragePolicyStd     | 0.76999   |
| AveragePolicyStd[0]  | 0.76999   |
| AverageReturn        | -203.94   |
| MinReturn            | -592.16   |
| MaxReturn            | -1.277    |
| StdReturn            | 136.26    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1440      |
| TotalNSamples        | 2.88e+05  |
| ExplainedVariance    | 0.96728   |
------------------------------------
[2021-12-20 17:01:11.181934 UTC] Saving snapshot
[2021-12-20 17:01:11.187695 UTC] Starting iteration 29
[2021-12-20 17:01:11.187868 UTC] Start collecting samples
[2021-12-20 17:01:12.754828 UTC] Computing input variables for policy optimization
[2021-12-20 17:01:12.827829 UTC] Performing policy update
[2021-12-20 17:01:12.828915 UTC] Computing gradient in Euclidean space
[2021-12-20 17:01:12.889141 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:01:13.498886 UTC] Performing line search
[2021-12-20 17:01:13.552261 UTC] Updating baseline
[2021-12-20 17:01:14.267757 UTC] Computing logging information
------------------------------------
| Iteration            | 29        |
| ExpectedImprovement  | 0.015538  |
| ActualImprovement    | 0.011452  |
| ImprovementRatio     | 0.737     |
| MeanKL               | 0.0091366 |
| Entropy              | 1.1486    |
| Perplexity           | 3.1536    |
| AveragePolicyStd     | 0.76309   |
| AveragePolicyStd[0]  | 0.76309   |
| AverageReturn        | -196.11   |
| MinReturn            | -503.91   |
| MaxReturn            | -0.99583  |
| StdReturn            | 116.26    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1488      |
| TotalNSamples        | 2.976e+05 |
| ExplainedVariance    | 0.86914   |
------------------------------------
[2021-12-20 17:01:14.336683 UTC] Saving snapshot
[2021-12-20 17:01:14.342144 UTC] Starting iteration 30
[2021-12-20 17:01:14.342374 UTC] Start collecting samples
[2021-12-20 17:01:16.002970 UTC] Computing input variables for policy optimization
[2021-12-20 17:01:16.068469 UTC] Performing policy update
[2021-12-20 17:01:16.070506 UTC] Computing gradient in Euclidean space
[2021-12-20 17:01:16.114915 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:01:16.635951 UTC] Performing line search
[2021-12-20 17:01:16.704056 UTC] Updating baseline
[2021-12-20 17:01:17.357918 UTC] Computing logging information
------------------------------------
| Iteration            | 30        |
| ExpectedImprovement  | 0.015473  |
| ActualImprovement    | 0.014096  |
| ImprovementRatio     | 0.911     |
| MeanKL               | 0.0067141 |
| Entropy              | 1.128     |
| Perplexity           | 3.0893    |
| AveragePolicyStd     | 0.74753   |
| AveragePolicyStd[0]  | 0.74753   |
| AverageReturn        | -197.14   |
| MinReturn            | -503.91   |
| MaxReturn            | -0.99583  |
| StdReturn            | 112.85    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1536      |
| TotalNSamples        | 3.072e+05 |
| ExplainedVariance    | 0.90637   |
------------------------------------
[2021-12-20 17:01:17.433712 UTC] Saving snapshot
[2021-12-20 17:01:17.441170 UTC] Starting iteration 31
[2021-12-20 17:01:17.441606 UTC] Start collecting samples
[2021-12-20 17:01:19.079145 UTC] Computing input variables for policy optimization
[2021-12-20 17:01:19.199629 UTC] Performing policy update
[2021-12-20 17:01:19.207557 UTC] Computing gradient in Euclidean space
[2021-12-20 17:01:19.278299 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:01:19.878188 UTC] Performing line search
[2021-12-20 17:01:19.909873 UTC] Updating baseline
[2021-12-20 17:01:20.545920 UTC] Computing logging information
------------------------------------
| Iteration            | 31        |
| ExpectedImprovement  | 0.015969  |
| ActualImprovement    | 0.015642  |
| ImprovementRatio     | 0.97952   |
| MeanKL               | 0.0095673 |
| Entropy              | 1.1189    |
| Perplexity           | 3.0615    |
| AveragePolicyStd     | 0.74079   |
| AveragePolicyStd[0]  | 0.74079   |
| AverageReturn        | -196.71   |
| MinReturn            | -499.54   |
| MaxReturn            | -0.82476  |
| StdReturn            | 114.64    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1600      |
| TotalNSamples        | 3.2e+05   |
| ExplainedVariance    | 0.93076   |
------------------------------------
[2021-12-20 17:01:20.622821 UTC] Saving snapshot
[2021-12-20 17:01:20.630527 UTC] Starting iteration 32
[2021-12-20 17:01:20.630776 UTC] Start collecting samples
[2021-12-20 17:01:22.384496 UTC] Computing input variables for policy optimization
[2021-12-20 17:01:22.459002 UTC] Performing policy update
[2021-12-20 17:01:22.461063 UTC] Computing gradient in Euclidean space
[2021-12-20 17:01:22.530168 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:01:23.187672 UTC] Performing line search
[2021-12-20 17:01:23.256365 UTC] Updating baseline
[2021-12-20 17:01:23.934490 UTC] Computing logging information
------------------------------------
| Iteration            | 32        |
| ExpectedImprovement  | 0.0096805 |
| ActualImprovement    | 0.01045   |
| ImprovementRatio     | 1.0794    |
| MeanKL               | 0.0072869 |
| Entropy              | 1.1133    |
| Perplexity           | 3.0443    |
| AveragePolicyStd     | 0.73663   |
| AveragePolicyStd[0]  | 0.73663   |
| AverageReturn        | -182.8    |
| MinReturn            | -499.54   |
| MaxReturn            | -0.82476  |
| StdReturn            | 114.19    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1648      |
| TotalNSamples        | 3.296e+05 |
| ExplainedVariance    | 0.96792   |
------------------------------------
[2021-12-20 17:01:24.025262 UTC] Saving snapshot
[2021-12-20 17:01:24.033677 UTC] Starting iteration 33
[2021-12-20 17:01:24.034573 UTC] Start collecting samples
[2021-12-20 17:01:26.446818 UTC] Computing input variables for policy optimization
[2021-12-20 17:01:26.591785 UTC] Performing policy update
[2021-12-20 17:01:26.593230 UTC] Computing gradient in Euclidean space
[2021-12-20 17:01:26.655813 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:01:27.293760 UTC] Performing line search
[2021-12-20 17:01:27.347183 UTC] Updating baseline
[2021-12-20 17:01:28.110674 UTC] Computing logging information
------------------------------------
| Iteration            | 33        |
| ExpectedImprovement  | 0.010321  |
| ActualImprovement    | 0.010002  |
| ImprovementRatio     | 0.96907   |
| MeanKL               | 0.0067222 |
| Entropy              | 1.0963    |
| Perplexity           | 2.993     |
| AveragePolicyStd     | 0.72422   |
| AveragePolicyStd[0]  | 0.72422   |
| AverageReturn        | -183.21   |
| MinReturn            | -453.56   |
| MaxReturn            | -0.87325  |
| StdReturn            | 116.27    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1696      |
| TotalNSamples        | 3.392e+05 |
| ExplainedVariance    | 0.97584   |
------------------------------------
[2021-12-20 17:01:28.201107 UTC] Saving snapshot
[2021-12-20 17:01:28.210828 UTC] Starting iteration 34
[2021-12-20 17:01:28.211245 UTC] Start collecting samples
[2021-12-20 17:01:31.782046 UTC] Computing input variables for policy optimization
[2021-12-20 17:01:31.908558 UTC] Performing policy update
[2021-12-20 17:01:31.909532 UTC] Computing gradient in Euclidean space
[2021-12-20 17:01:31.970217 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:01:32.640247 UTC] Performing line search
[2021-12-20 17:01:32.674620 UTC] Updating baseline
[2021-12-20 17:01:33.926598 UTC] Computing logging information
------------------------------------
| Iteration            | 34        |
| ExpectedImprovement  | 0.016991  |
| ActualImprovement    | 0.015236  |
| ImprovementRatio     | 0.89669   |
| MeanKL               | 0.0096345 |
| Entropy              | 1.0764    |
| Perplexity           | 2.934     |
| AveragePolicyStd     | 0.70994   |
| AveragePolicyStd[0]  | 0.70994   |
| AverageReturn        | -183.78   |
| MinReturn            | -427.68   |
| MaxReturn            | -0.87325  |
| StdReturn            | 122.69    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1744      |
| TotalNSamples        | 3.488e+05 |
| ExplainedVariance    | 0.96083   |
------------------------------------
[2021-12-20 17:01:33.992236 UTC] Saving snapshot
[2021-12-20 17:01:34.006763 UTC] Starting iteration 35
[2021-12-20 17:01:34.014108 UTC] Start collecting samples
[2021-12-20 17:01:36.667712 UTC] Computing input variables for policy optimization
[2021-12-20 17:01:36.721035 UTC] Performing policy update
[2021-12-20 17:01:36.721725 UTC] Computing gradient in Euclidean space
[2021-12-20 17:01:36.770349 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:01:37.273343 UTC] Performing line search
[2021-12-20 17:01:37.298843 UTC] Updating baseline
[2021-12-20 17:01:37.862403 UTC] Computing logging information
------------------------------------
| Iteration            | 35        |
| ExpectedImprovement  | 0.012859  |
| ActualImprovement    | 0.023755  |
| ImprovementRatio     | 1.8473    |
| MeanKL               | 0.0089048 |
| Entropy              | 1.0783    |
| Perplexity           | 2.9397    |
| AveragePolicyStd     | 0.71131   |
| AveragePolicyStd[0]  | 0.71131   |
| AverageReturn        | -173.15   |
| MinReturn            | -427.68   |
| MaxReturn            | -1.0738   |
| StdReturn            | 119.27    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1792      |
| TotalNSamples        | 3.584e+05 |
| ExplainedVariance    | 0.97794   |
------------------------------------
[2021-12-20 17:01:37.943573 UTC] Saving snapshot
[2021-12-20 17:01:37.950055 UTC] Starting iteration 36
[2021-12-20 17:01:37.951602 UTC] Start collecting samples
[2021-12-20 17:01:39.752969 UTC] Computing input variables for policy optimization
[2021-12-20 17:01:39.808833 UTC] Performing policy update
[2021-12-20 17:01:39.812233 UTC] Computing gradient in Euclidean space
[2021-12-20 17:01:39.891159 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:01:40.518571 UTC] Performing line search
[2021-12-20 17:01:40.544243 UTC] Updating baseline
[2021-12-20 17:01:41.274289 UTC] Computing logging information
------------------------------------
| Iteration            | 36        |
| ExpectedImprovement  | 0.020229  |
| ActualImprovement    | 0.017484  |
| ImprovementRatio     | 0.8643    |
| MeanKL               | 0.0088394 |
| Entropy              | 1.0805    |
| Perplexity           | 2.946     |
| AveragePolicyStd     | 0.71285   |
| AveragePolicyStd[0]  | 0.71285   |
| AverageReturn        | -171.05   |
| MinReturn            | -380.61   |
| MaxReturn            | -1.0738   |
| StdReturn            | 106.71    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1840      |
| TotalNSamples        | 3.68e+05  |
| ExplainedVariance    | 0.98196   |
------------------------------------
[2021-12-20 17:01:41.386041 UTC] Saving snapshot
[2021-12-20 17:01:41.391476 UTC] Starting iteration 37
[2021-12-20 17:01:41.391900 UTC] Start collecting samples
[2021-12-20 17:01:43.433161 UTC] Computing input variables for policy optimization
[2021-12-20 17:01:43.517469 UTC] Performing policy update
[2021-12-20 17:01:43.533575 UTC] Computing gradient in Euclidean space
[2021-12-20 17:01:43.594550 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:01:44.090682 UTC] Performing line search
[2021-12-20 17:01:44.123037 UTC] Updating baseline
[2021-12-20 17:01:44.760091 UTC] Computing logging information
------------------------------------
| Iteration            | 37        |
| ExpectedImprovement  | 0.019131  |
| ActualImprovement    | 0.021556  |
| ImprovementRatio     | 1.1268    |
| MeanKL               | 0.0093006 |
| Entropy              | 1.0731    |
| Perplexity           | 2.9244    |
| AveragePolicyStd     | 0.70761   |
| AveragePolicyStd[0]  | 0.70761   |
| AverageReturn        | -190.13   |
| MinReturn            | -636.57   |
| MaxReturn            | -1.1978   |
| StdReturn            | 117.02    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1888      |
| TotalNSamples        | 3.776e+05 |
| ExplainedVariance    | 0.57676   |
------------------------------------
[2021-12-20 17:01:44.823303 UTC] Saving snapshot
[2021-12-20 17:01:44.828176 UTC] Starting iteration 38
[2021-12-20 17:01:44.828326 UTC] Start collecting samples
[2021-12-20 17:01:47.467649 UTC] Computing input variables for policy optimization
[2021-12-20 17:01:47.537322 UTC] Performing policy update
[2021-12-20 17:01:47.538443 UTC] Computing gradient in Euclidean space
[2021-12-20 17:01:47.603496 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:01:48.338748 UTC] Performing line search
[2021-12-20 17:01:48.384841 UTC] Updating baseline
[2021-12-20 17:01:49.084073 UTC] Computing logging information
------------------------------------
| Iteration            | 38        |
| ExpectedImprovement  | 0.01213   |
| ActualImprovement    | 0.014009  |
| ImprovementRatio     | 1.155     |
| MeanKL               | 0.0099813 |
| Entropy              | 1.0842    |
| Perplexity           | 2.957     |
| AveragePolicyStd     | 0.71551   |
| AveragePolicyStd[0]  | 0.71551   |
| AverageReturn        | -203.27   |
| MinReturn            | -879.66   |
| MaxReturn            | -1.1113   |
| StdReturn            | 145.76    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 1936      |
| TotalNSamples        | 3.872e+05 |
| ExplainedVariance    | 0.83887   |
------------------------------------
[2021-12-20 17:01:49.154383 UTC] Saving snapshot
[2021-12-20 17:01:49.170033 UTC] Starting iteration 39
[2021-12-20 17:01:49.170266 UTC] Start collecting samples
[2021-12-20 17:01:51.453551 UTC] Computing input variables for policy optimization
[2021-12-20 17:01:51.512016 UTC] Performing policy update
[2021-12-20 17:01:51.512838 UTC] Computing gradient in Euclidean space
[2021-12-20 17:01:51.560917 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:01:52.322849 UTC] Performing line search
[2021-12-20 17:01:52.403210 UTC] Updating baseline
[2021-12-20 17:01:53.290893 UTC] Computing logging information
------------------------------------
| Iteration            | 39        |
| ExpectedImprovement  | 0.015175  |
| ActualImprovement    | 0.023778  |
| ImprovementRatio     | 1.567     |
| MeanKL               | 0.0064388 |
| Entropy              | 1.0941    |
| Perplexity           | 2.9864    |
| AveragePolicyStd     | 0.72261   |
| AveragePolicyStd[0]  | 0.72261   |
| AverageReturn        | -155.98   |
| MinReturn            | -625.51   |
| MaxReturn            | -0.78912  |
| StdReturn            | 105.4     |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2000      |
| TotalNSamples        | 4e+05     |
| ExplainedVariance    | 0.95814   |
------------------------------------
[2021-12-20 17:01:53.404025 UTC] Saving snapshot
[2021-12-20 17:01:53.409870 UTC] Starting iteration 40
[2021-12-20 17:01:53.410053 UTC] Start collecting samples
[2021-12-20 17:01:55.871300 UTC] Computing input variables for policy optimization
[2021-12-20 17:01:55.973085 UTC] Performing policy update
[2021-12-20 17:01:55.997882 UTC] Computing gradient in Euclidean space
[2021-12-20 17:01:56.078347 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:01:56.957973 UTC] Performing line search
[2021-12-20 17:01:56.994508 UTC] Updating baseline
[2021-12-20 17:01:58.188028 UTC] Computing logging information
------------------------------------
| Iteration            | 40        |
| ExpectedImprovement  | 0.014277  |
| ActualImprovement    | 0.011879  |
| ImprovementRatio     | 0.83203   |
| MeanKL               | 0.0097224 |
| Entropy              | 1.0951    |
| Perplexity           | 2.9894    |
| AveragePolicyStd     | 0.72335   |
| AveragePolicyStd[0]  | 0.72335   |
| AverageReturn        | -155.64   |
| MinReturn            | -376.98   |
| MaxReturn            | -0.79719  |
| StdReturn            | 96.788    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2048      |
| TotalNSamples        | 4.096e+05 |
| ExplainedVariance    | 0.966     |
------------------------------------
[2021-12-20 17:01:58.398925 UTC] Saving snapshot
[2021-12-20 17:01:58.417898 UTC] Starting iteration 41
[2021-12-20 17:01:58.419636 UTC] Start collecting samples
[2021-12-20 17:02:03.120389 UTC] Computing input variables for policy optimization
[2021-12-20 17:02:03.190900 UTC] Performing policy update
[2021-12-20 17:02:03.192712 UTC] Computing gradient in Euclidean space
[2021-12-20 17:02:03.290828 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:02:04.414924 UTC] Performing line search
[2021-12-20 17:02:04.484116 UTC] Updating baseline
[2021-12-20 17:02:05.667295 UTC] Computing logging information
------------------------------------
| Iteration            | 41        |
| ExpectedImprovement  | 0.017027  |
| ActualImprovement    | 0.015091  |
| ImprovementRatio     | 0.88628   |
| MeanKL               | 0.0092057 |
| Entropy              | 1.0687    |
| Perplexity           | 2.9117    |
| AveragePolicyStd     | 0.70455   |
| AveragePolicyStd[0]  | 0.70455   |
| AverageReturn        | -179.5    |
| MinReturn            | -383.9    |
| MaxReturn            | -1.0807   |
| StdReturn            | 100.46    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2096      |
| TotalNSamples        | 4.192e+05 |
| ExplainedVariance    | 0.97402   |
------------------------------------
[2021-12-20 17:02:05.758864 UTC] Saving snapshot
[2021-12-20 17:02:05.771816 UTC] Starting iteration 42
[2021-12-20 17:02:05.772101 UTC] Start collecting samples
[2021-12-20 17:02:09.802694 UTC] Computing input variables for policy optimization
[2021-12-20 17:02:09.859270 UTC] Performing policy update
[2021-12-20 17:02:09.859992 UTC] Computing gradient in Euclidean space
[2021-12-20 17:02:09.931102 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:02:10.549590 UTC] Performing line search
[2021-12-20 17:02:10.590313 UTC] Updating baseline
[2021-12-20 17:02:11.550920 UTC] Computing logging information
------------------------------------
| Iteration            | 42        |
| ExpectedImprovement  | 0.021011  |
| ActualImprovement    | 0.019559  |
| ImprovementRatio     | 0.93088   |
| MeanKL               | 0.0094131 |
| Entropy              | 1.0562    |
| Perplexity           | 2.8754    |
| AveragePolicyStd     | 0.69577   |
| AveragePolicyStd[0]  | 0.69577   |
| AverageReturn        | -175.13   |
| MinReturn            | -383.9    |
| MaxReturn            | -1.0662   |
| StdReturn            | 93.452    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2144      |
| TotalNSamples        | 4.288e+05 |
| ExplainedVariance    | 0.97568   |
------------------------------------
[2021-12-20 17:02:11.710681 UTC] Saving snapshot
[2021-12-20 17:02:11.722250 UTC] Starting iteration 43
[2021-12-20 17:02:11.722689 UTC] Start collecting samples
[2021-12-20 17:02:15.837481 UTC] Computing input variables for policy optimization
[2021-12-20 17:02:15.913044 UTC] Performing policy update
[2021-12-20 17:02:15.914211 UTC] Computing gradient in Euclidean space
[2021-12-20 17:02:15.966697 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:02:16.612336 UTC] Performing line search
[2021-12-20 17:02:16.693102 UTC] Updating baseline
[2021-12-20 17:02:17.416348 UTC] Computing logging information
------------------------------------
| Iteration            | 43        |
| ExpectedImprovement  | 0.011891  |
| ActualImprovement    | 0.010964  |
| ImprovementRatio     | 0.92208   |
| MeanKL               | 0.0072797 |
| Entropy              | 1.0468    |
| Perplexity           | 2.8484    |
| AveragePolicyStd     | 0.68924   |
| AveragePolicyStd[0]  | 0.68924   |
| AverageReturn        | -159.09   |
| MinReturn            | -389.49   |
| MaxReturn            | -0.81517  |
| StdReturn            | 100.04    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2192      |
| TotalNSamples        | 4.384e+05 |
| ExplainedVariance    | 0.97965   |
------------------------------------
[2021-12-20 17:02:17.499475 UTC] Saving snapshot
[2021-12-20 17:02:17.505492 UTC] Starting iteration 44
[2021-12-20 17:02:17.506068 UTC] Start collecting samples
[2021-12-20 17:02:20.903840 UTC] Computing input variables for policy optimization
[2021-12-20 17:02:20.971065 UTC] Performing policy update
[2021-12-20 17:02:20.972112 UTC] Computing gradient in Euclidean space
[2021-12-20 17:02:21.087007 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:02:21.941254 UTC] Performing line search
[2021-12-20 17:02:22.023168 UTC] Updating baseline
[2021-12-20 17:02:22.958564 UTC] Computing logging information
------------------------------------
| Iteration            | 44        |
| ExpectedImprovement  | 0.012335  |
| ActualImprovement    | 0.01059   |
| ImprovementRatio     | 0.85856   |
| MeanKL               | 0.0077021 |
| Entropy              | 1.0258    |
| Perplexity           | 2.7892    |
| AveragePolicyStd     | 0.67491   |
| AveragePolicyStd[0]  | 0.67491   |
| AverageReturn        | -162.09   |
| MinReturn            | -389.49   |
| MaxReturn            | -0.81517  |
| StdReturn            | 101.99    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2240      |
| TotalNSamples        | 4.48e+05  |
| ExplainedVariance    | 0.97332   |
------------------------------------
[2021-12-20 17:02:23.057465 UTC] Saving snapshot
[2021-12-20 17:02:23.072773 UTC] Starting iteration 45
[2021-12-20 17:02:23.073213 UTC] Start collecting samples
[2021-12-20 17:02:26.623953 UTC] Computing input variables for policy optimization
[2021-12-20 17:02:26.719319 UTC] Performing policy update
[2021-12-20 17:02:26.725362 UTC] Computing gradient in Euclidean space
[2021-12-20 17:02:26.788000 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:02:27.673849 UTC] Performing line search
[2021-12-20 17:02:27.987206 UTC] Updating baseline
[2021-12-20 17:02:28.931911 UTC] Computing logging information
------------------------------------
| Iteration            | 45        |
| ExpectedImprovement  | 0.017502  |
| ActualImprovement    | 0.013417  |
| ImprovementRatio     | 0.76661   |
| MeanKL               | 0.0065791 |
| Entropy              | 1.0192    |
| Perplexity           | 2.7709    |
| AveragePolicyStd     | 0.67047   |
| AveragePolicyStd[0]  | 0.67047   |
| AverageReturn        | -172.82   |
| MinReturn            | -353.98   |
| MaxReturn            | -0.89011  |
| StdReturn            | 89.7      |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2288      |
| TotalNSamples        | 4.576e+05 |
| ExplainedVariance    | 0.95528   |
------------------------------------
[2021-12-20 17:02:29.163068 UTC] Saving snapshot
[2021-12-20 17:02:29.168038 UTC] Starting iteration 46
[2021-12-20 17:02:29.168404 UTC] Start collecting samples
[2021-12-20 17:02:32.340383 UTC] Computing input variables for policy optimization
[2021-12-20 17:02:32.421728 UTC] Performing policy update
[2021-12-20 17:02:32.430360 UTC] Computing gradient in Euclidean space
[2021-12-20 17:02:32.496799 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:02:33.087228 UTC] Performing line search
[2021-12-20 17:02:33.141677 UTC] Updating baseline
[2021-12-20 17:02:33.939397 UTC] Computing logging information
------------------------------------
| Iteration            | 46        |
| ExpectedImprovement  | 0.012792  |
| ActualImprovement    | 0.0088757 |
| ImprovementRatio     | 0.69385   |
| MeanKL               | 0.0064649 |
| Entropy              | 1.001     |
| Perplexity           | 2.721     |
| AveragePolicyStd     | 0.65841   |
| AveragePolicyStd[0]  | 0.65841   |
| AverageReturn        | -169.42   |
| MinReturn            | -431.97   |
| MaxReturn            | -0.89011  |
| StdReturn            | 97.894    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2336      |
| TotalNSamples        | 4.672e+05 |
| ExplainedVariance    | 0.98166   |
------------------------------------
[2021-12-20 17:02:34.008090 UTC] Saving snapshot
[2021-12-20 17:02:34.014821 UTC] Starting iteration 47
[2021-12-20 17:02:34.015030 UTC] Start collecting samples
[2021-12-20 17:02:35.687206 UTC] Computing input variables for policy optimization
[2021-12-20 17:02:35.764523 UTC] Performing policy update
[2021-12-20 17:02:35.765363 UTC] Computing gradient in Euclidean space
[2021-12-20 17:02:35.850737 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:02:36.535209 UTC] Performing line search
[2021-12-20 17:02:36.579646 UTC] Updating baseline
[2021-12-20 17:02:37.175910 UTC] Computing logging information
------------------------------------
| Iteration            | 47        |
| ExpectedImprovement  | 0.021841  |
| ActualImprovement    | 0.029452  |
| ImprovementRatio     | 1.3485    |
| MeanKL               | 0.0096727 |
| Entropy              | 0.98132   |
| Perplexity           | 2.668     |
| AveragePolicyStd     | 0.64557   |
| AveragePolicyStd[0]  | 0.64557   |
| AverageReturn        | -153.42   |
| MinReturn            | -431.97   |
| MaxReturn            | -0.93339  |
| StdReturn            | 93.732    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2400      |
| TotalNSamples        | 4.8e+05   |
| ExplainedVariance    | 0.97885   |
------------------------------------
[2021-12-20 17:02:37.258442 UTC] Saving snapshot
[2021-12-20 17:02:37.265213 UTC] Starting iteration 48
[2021-12-20 17:02:37.267632 UTC] Start collecting samples
[2021-12-20 17:02:38.862495 UTC] Computing input variables for policy optimization
[2021-12-20 17:02:38.931315 UTC] Performing policy update
[2021-12-20 17:02:38.933836 UTC] Computing gradient in Euclidean space
[2021-12-20 17:02:38.984507 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:02:39.777701 UTC] Performing line search
[2021-12-20 17:02:39.806201 UTC] Updating baseline
[2021-12-20 17:02:40.478012 UTC] Computing logging information
------------------------------------
| Iteration            | 48        |
| ExpectedImprovement  | 0.017133  |
| ActualImprovement    | 0.016831  |
| ImprovementRatio     | 0.98241   |
| MeanKL               | 0.0098023 |
| Entropy              | 0.97838   |
| Perplexity           | 2.6602    |
| AveragePolicyStd     | 0.64368   |
| AveragePolicyStd[0]  | 0.64368   |
| AverageReturn        | -145.22   |
| MinReturn            | -375.12   |
| MaxReturn            | -0.85893  |
| StdReturn            | 90.508    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2448      |
| TotalNSamples        | 4.896e+05 |
| ExplainedVariance    | 0.98814   |
------------------------------------
[2021-12-20 17:02:40.549432 UTC] Saving snapshot
[2021-12-20 17:02:40.560106 UTC] Starting iteration 49
[2021-12-20 17:02:40.560700 UTC] Start collecting samples
[2021-12-20 17:02:42.446047 UTC] Computing input variables for policy optimization
[2021-12-20 17:02:42.515474 UTC] Performing policy update
[2021-12-20 17:02:42.516152 UTC] Computing gradient in Euclidean space
[2021-12-20 17:02:42.562578 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:02:43.061693 UTC] Performing line search
[2021-12-20 17:02:43.144598 UTC] Updating baseline
[2021-12-20 17:02:43.941682 UTC] Computing logging information
------------------------------------
| Iteration            | 49        |
| ExpectedImprovement  | 0.01311   |
| ActualImprovement    | 0.011557  |
| ImprovementRatio     | 0.88153   |
| MeanKL               | 0.0069328 |
| Entropy              | 0.96503   |
| Perplexity           | 2.6249    |
| AveragePolicyStd     | 0.63514   |
| AveragePolicyStd[0]  | 0.63514   |
| AverageReturn        | -152.76   |
| MinReturn            | -349.45   |
| MaxReturn            | -0.85893  |
| StdReturn            | 87.386    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2496      |
| TotalNSamples        | 4.992e+05 |
| ExplainedVariance    | 0.93338   |
------------------------------------
[2021-12-20 17:02:44.028922 UTC] Saving snapshot
[2021-12-20 17:02:44.038183 UTC] Starting iteration 50
[2021-12-20 17:02:44.038822 UTC] Start collecting samples
[2021-12-20 17:02:45.730660 UTC] Computing input variables for policy optimization
[2021-12-20 17:02:45.786987 UTC] Performing policy update
[2021-12-20 17:02:45.791745 UTC] Computing gradient in Euclidean space
[2021-12-20 17:02:45.853998 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:02:46.441952 UTC] Performing line search
[2021-12-20 17:02:46.474740 UTC] Updating baseline
[2021-12-20 17:02:47.244296 UTC] Computing logging information
------------------------------------
| Iteration            | 50        |
| ExpectedImprovement  | 0.018483  |
| ActualImprovement    | 0.013719  |
| ImprovementRatio     | 0.74228   |
| MeanKL               | 0.0098588 |
| Entropy              | 0.92791   |
| Perplexity           | 2.5292    |
| AveragePolicyStd     | 0.612     |
| AveragePolicyStd[0]  | 0.612     |
| AverageReturn        | -151.02   |
| MinReturn            | -367.45   |
| MaxReturn            | -0.72523  |
| StdReturn            | 85.767    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2544      |
| TotalNSamples        | 5.088e+05 |
| ExplainedVariance    | 0.97313   |
------------------------------------
[2021-12-20 17:02:47.336251 UTC] Saving snapshot
[2021-12-20 17:02:47.352513 UTC] Starting iteration 51
[2021-12-20 17:02:47.353624 UTC] Start collecting samples
[2021-12-20 17:02:49.028651 UTC] Computing input variables for policy optimization
[2021-12-20 17:02:49.112308 UTC] Performing policy update
[2021-12-20 17:02:49.113294 UTC] Computing gradient in Euclidean space
[2021-12-20 17:02:49.178307 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:02:49.730132 UTC] Performing line search
[2021-12-20 17:02:49.788186 UTC] Updating baseline
[2021-12-20 17:02:50.422584 UTC] Computing logging information
------------------------------------
| Iteration            | 51        |
| ExpectedImprovement  | 0.010035  |
| ActualImprovement    | 0.011014  |
| ImprovementRatio     | 1.0976    |
| MeanKL               | 0.0065598 |
| Entropy              | 0.89142   |
| Perplexity           | 2.4386    |
| AveragePolicyStd     | 0.59007   |
| AveragePolicyStd[0]  | 0.59007   |
| AverageReturn        | -149.39   |
| MinReturn            | -373.34   |
| MaxReturn            | -0.64963  |
| StdReturn            | 90.132    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2592      |
| TotalNSamples        | 5.184e+05 |
| ExplainedVariance    | 0.98364   |
------------------------------------
[2021-12-20 17:02:50.509367 UTC] Saving snapshot
[2021-12-20 17:02:50.516910 UTC] Starting iteration 52
[2021-12-20 17:02:50.517237 UTC] Start collecting samples
[2021-12-20 17:02:52.487559 UTC] Computing input variables for policy optimization
[2021-12-20 17:02:52.565194 UTC] Performing policy update
[2021-12-20 17:02:52.566669 UTC] Computing gradient in Euclidean space
[2021-12-20 17:02:52.634874 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:02:53.243777 UTC] Performing line search
[2021-12-20 17:02:53.320036 UTC] Updating baseline
[2021-12-20 17:02:53.951822 UTC] Computing logging information
------------------------------------
| Iteration            | 52        |
| ExpectedImprovement  | 0.011884  |
| ActualImprovement    | 0.01032   |
| ImprovementRatio     | 0.86844   |
| MeanKL               | 0.0064958 |
| Entropy              | 0.87321   |
| Perplexity           | 2.3946    |
| AveragePolicyStd     | 0.57942   |
| AveragePolicyStd[0]  | 0.57942   |
| AverageReturn        | -153.82   |
| MinReturn            | -373.34   |
| MaxReturn            | -0.64963  |
| StdReturn            | 91.143    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2640      |
| TotalNSamples        | 5.28e+05  |
| ExplainedVariance    | 0.96688   |
------------------------------------
[2021-12-20 17:02:54.045666 UTC] Saving snapshot
[2021-12-20 17:02:54.055422 UTC] Starting iteration 53
[2021-12-20 17:02:54.062054 UTC] Start collecting samples
[2021-12-20 17:02:55.749947 UTC] Computing input variables for policy optimization
[2021-12-20 17:02:55.807854 UTC] Performing policy update
[2021-12-20 17:02:55.819663 UTC] Computing gradient in Euclidean space
[2021-12-20 17:02:55.875623 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:02:56.449926 UTC] Performing line search
[2021-12-20 17:02:56.527863 UTC] Updating baseline
[2021-12-20 17:02:57.176694 UTC] Computing logging information
------------------------------------
| Iteration            | 53        |
| ExpectedImprovement  | 0.011264  |
| ActualImprovement    | 0.010883  |
| ImprovementRatio     | 0.96615   |
| MeanKL               | 0.006992  |
| Entropy              | 0.85048   |
| Perplexity           | 2.3408    |
| AveragePolicyStd     | 0.5664    |
| AveragePolicyStd[0]  | 0.5664    |
| AverageReturn        | -167.16   |
| MinReturn            | -385.34   |
| MaxReturn            | -0.91965  |
| StdReturn            | 93.039    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2688      |
| TotalNSamples        | 5.376e+05 |
| ExplainedVariance    | 0.98803   |
------------------------------------
[2021-12-20 17:02:57.276514 UTC] Saving snapshot
[2021-12-20 17:02:57.285809 UTC] Starting iteration 54
[2021-12-20 17:02:57.287147 UTC] Start collecting samples
[2021-12-20 17:02:59.112211 UTC] Computing input variables for policy optimization
[2021-12-20 17:02:59.183638 UTC] Performing policy update
[2021-12-20 17:02:59.184511 UTC] Computing gradient in Euclidean space
[2021-12-20 17:02:59.231078 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:02:59.747980 UTC] Performing line search
[2021-12-20 17:02:59.773693 UTC] Updating baseline
[2021-12-20 17:03:00.337778 UTC] Computing logging information
------------------------------------
| Iteration            | 54        |
| ExpectedImprovement  | 0.019053  |
| ActualImprovement    | 0.022363  |
| ImprovementRatio     | 1.1737    |
| MeanKL               | 0.0092374 |
| Entropy              | 0.8212    |
| Perplexity           | 2.2732    |
| AveragePolicyStd     | 0.55005   |
| AveragePolicyStd[0]  | 0.55005   |
| AverageReturn        | -176.78   |
| MinReturn            | -409.38   |
| MaxReturn            | -0.53318  |
| StdReturn            | 99.583    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2736      |
| TotalNSamples        | 5.472e+05 |
| ExplainedVariance    | 0.97733   |
------------------------------------
[2021-12-20 17:03:00.402779 UTC] Saving snapshot
[2021-12-20 17:03:00.409615 UTC] Starting iteration 55
[2021-12-20 17:03:00.411178 UTC] Start collecting samples
[2021-12-20 17:03:02.222372 UTC] Computing input variables for policy optimization
[2021-12-20 17:03:02.304081 UTC] Performing policy update
[2021-12-20 17:03:02.309205 UTC] Computing gradient in Euclidean space
[2021-12-20 17:03:02.375220 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:03:03.099625 UTC] Performing line search
[2021-12-20 17:03:03.153274 UTC] Updating baseline
[2021-12-20 17:03:03.840452 UTC] Computing logging information
------------------------------------
| Iteration            | 55        |
| ExpectedImprovement  | 0.015408  |
| ActualImprovement    | 0.017326  |
| ImprovementRatio     | 1.1245    |
| MeanKL               | 0.0095422 |
| Entropy              | 0.83307   |
| Perplexity           | 2.3004    |
| AveragePolicyStd     | 0.55662   |
| AveragePolicyStd[0]  | 0.55662   |
| AverageReturn        | -168.54   |
| MinReturn            | -401.99   |
| MaxReturn            | -0.53318  |
| StdReturn            | 91.252    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2800      |
| TotalNSamples        | 5.6e+05   |
| ExplainedVariance    | 0.98223   |
------------------------------------
[2021-12-20 17:03:03.923817 UTC] Saving snapshot
[2021-12-20 17:03:03.936151 UTC] Starting iteration 56
[2021-12-20 17:03:03.936439 UTC] Start collecting samples
[2021-12-20 17:03:05.831015 UTC] Computing input variables for policy optimization
[2021-12-20 17:03:05.887880 UTC] Performing policy update
[2021-12-20 17:03:05.895191 UTC] Computing gradient in Euclidean space
[2021-12-20 17:03:05.953304 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:03:06.513881 UTC] Performing line search
[2021-12-20 17:03:06.562828 UTC] Updating baseline
[2021-12-20 17:03:07.149650 UTC] Computing logging information
------------------------------------
| Iteration            | 56        |
| ExpectedImprovement  | 0.019529  |
| ActualImprovement    | 0.020117  |
| ImprovementRatio     | 1.0301    |
| MeanKL               | 0.0097069 |
| Entropy              | 0.84261   |
| Perplexity           | 2.3224    |
| AveragePolicyStd     | 0.56196   |
| AveragePolicyStd[0]  | 0.56196   |
| AverageReturn        | -157.52   |
| MinReturn            | -381.02   |
| MaxReturn            | -0.54311  |
| StdReturn            | 81.397    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2848      |
| TotalNSamples        | 5.696e+05 |
| ExplainedVariance    | 0.99305   |
------------------------------------
[2021-12-20 17:03:07.220773 UTC] Saving snapshot
[2021-12-20 17:03:07.229435 UTC] Starting iteration 57
[2021-12-20 17:03:07.229668 UTC] Start collecting samples
[2021-12-20 17:03:09.314368 UTC] Computing input variables for policy optimization
[2021-12-20 17:03:09.384362 UTC] Performing policy update
[2021-12-20 17:03:09.390658 UTC] Computing gradient in Euclidean space
[2021-12-20 17:03:09.440479 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:03:10.055122 UTC] Performing line search
[2021-12-20 17:03:10.087038 UTC] Updating baseline
[2021-12-20 17:03:10.745283 UTC] Computing logging information
------------------------------------
| Iteration            | 57        |
| ExpectedImprovement  | 0.017322  |
| ActualImprovement    | 0.014199  |
| ImprovementRatio     | 0.81969   |
| MeanKL               | 0.009855  |
| Entropy              | 0.85365   |
| Perplexity           | 2.3482    |
| AveragePolicyStd     | 0.56819   |
| AveragePolicyStd[0]  | 0.56819   |
| AverageReturn        | -155.74   |
| MinReturn            | -372.71   |
| MaxReturn            | -0.73363  |
| StdReturn            | 80.289    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2896      |
| TotalNSamples        | 5.792e+05 |
| ExplainedVariance    | 0.98662   |
------------------------------------
[2021-12-20 17:03:10.830448 UTC] Saving snapshot
[2021-12-20 17:03:10.837251 UTC] Starting iteration 58
[2021-12-20 17:03:10.837986 UTC] Start collecting samples
[2021-12-20 17:03:12.550751 UTC] Computing input variables for policy optimization
[2021-12-20 17:03:12.607630 UTC] Performing policy update
[2021-12-20 17:03:12.610101 UTC] Computing gradient in Euclidean space
[2021-12-20 17:03:12.655498 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:03:13.264383 UTC] Performing line search
[2021-12-20 17:03:13.307497 UTC] Updating baseline
[2021-12-20 17:03:14.093078 UTC] Computing logging information
------------------------------------
| Iteration            | 58        |
| ExpectedImprovement  | 0.0093757 |
| ActualImprovement    | 0.0077888 |
| ImprovementRatio     | 0.83074   |
| MeanKL               | 0.0094979 |
| Entropy              | 0.85845   |
| Perplexity           | 2.3595    |
| AveragePolicyStd     | 0.57093   |
| AveragePolicyStd[0]  | 0.57093   |
| AverageReturn        | -164.46   |
| MinReturn            | -404.57   |
| MaxReturn            | -0.73363  |
| StdReturn            | 97.87     |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2944      |
| TotalNSamples        | 5.888e+05 |
| ExplainedVariance    | 0.98468   |
------------------------------------
[2021-12-20 17:03:14.188112 UTC] Saving snapshot
[2021-12-20 17:03:14.196259 UTC] Starting iteration 59
[2021-12-20 17:03:14.197168 UTC] Start collecting samples
[2021-12-20 17:03:15.908517 UTC] Computing input variables for policy optimization
[2021-12-20 17:03:15.983465 UTC] Performing policy update
[2021-12-20 17:03:15.985391 UTC] Computing gradient in Euclidean space
[2021-12-20 17:03:16.038686 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:03:16.554565 UTC] Performing line search
[2021-12-20 17:03:16.606477 UTC] Updating baseline
[2021-12-20 17:03:17.175215 UTC] Computing logging information
------------------------------------
| Iteration            | 59        |
| ExpectedImprovement  | 0.010652  |
| ActualImprovement    | 0.010229  |
| ImprovementRatio     | 0.96034   |
| MeanKL               | 0.0064388 |
| Entropy              | 0.87359   |
| Perplexity           | 2.3955    |
| AveragePolicyStd     | 0.57964   |
| AveragePolicyStd[0]  | 0.57964   |
| AverageReturn        | -146.71   |
| MinReturn            | -404.57   |
| MaxReturn            | -0.74029  |
| StdReturn            | 93.954    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 2992      |
| TotalNSamples        | 5.984e+05 |
| ExplainedVariance    | 0.98418   |
------------------------------------
[2021-12-20 17:03:17.261402 UTC] Saving snapshot
[2021-12-20 17:03:17.266413 UTC] Starting iteration 60
[2021-12-20 17:03:17.266562 UTC] Start collecting samples
[2021-12-20 17:03:19.029193 UTC] Computing input variables for policy optimization
[2021-12-20 17:03:19.174791 UTC] Performing policy update
[2021-12-20 17:03:19.184011 UTC] Computing gradient in Euclidean space
[2021-12-20 17:03:19.268959 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:03:20.097338 UTC] Performing line search
[2021-12-20 17:03:20.184137 UTC] Updating baseline
[2021-12-20 17:03:20.940004 UTC] Computing logging information
------------------------------------
| Iteration            | 60        |
| ExpectedImprovement  | 0.012291  |
| ActualImprovement    | 0.010928  |
| ImprovementRatio     | 0.88917   |
| MeanKL               | 0.0081031 |
| Entropy              | 0.85298   |
| Perplexity           | 2.3466    |
| AveragePolicyStd     | 0.56782   |
| AveragePolicyStd[0]  | 0.56782   |
| AverageReturn        | -148.45   |
| MinReturn            | -404.57   |
| MaxReturn            | -0.74029  |
| StdReturn            | 90.739    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3040      |
| TotalNSamples        | 6.08e+05  |
| ExplainedVariance    | 0.97364   |
------------------------------------
[2021-12-20 17:03:21.060143 UTC] Saving snapshot
[2021-12-20 17:03:21.067046 UTC] Starting iteration 61
[2021-12-20 17:03:21.069861 UTC] Start collecting samples
[2021-12-20 17:03:22.964550 UTC] Computing input variables for policy optimization
[2021-12-20 17:03:23.064596 UTC] Performing policy update
[2021-12-20 17:03:23.066005 UTC] Computing gradient in Euclidean space
[2021-12-20 17:03:23.121293 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:03:23.812607 UTC] Performing line search
[2021-12-20 17:03:23.861381 UTC] Updating baseline
[2021-12-20 17:03:24.611364 UTC] Computing logging information
------------------------------------
| Iteration            | 61        |
| ExpectedImprovement  | 0.017427  |
| ActualImprovement    | 0.019013  |
| ImprovementRatio     | 1.091     |
| MeanKL               | 0.0098561 |
| Entropy              | 0.84244   |
| Perplexity           | 2.322     |
| AveragePolicyStd     | 0.56186   |
| AveragePolicyStd[0]  | 0.56186   |
| AverageReturn        | -166.26   |
| MinReturn            | -381.83   |
| MaxReturn            | -0.74867  |
| StdReturn            | 96.932    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3088      |
| TotalNSamples        | 6.176e+05 |
| ExplainedVariance    | 0.991     |
------------------------------------
[2021-12-20 17:03:24.730006 UTC] Saving snapshot
[2021-12-20 17:03:24.745759 UTC] Starting iteration 62
[2021-12-20 17:03:24.746288 UTC] Start collecting samples
[2021-12-20 17:03:26.849747 UTC] Computing input variables for policy optimization
[2021-12-20 17:03:26.937312 UTC] Performing policy update
[2021-12-20 17:03:26.938124 UTC] Computing gradient in Euclidean space
[2021-12-20 17:03:26.986072 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:03:27.504009 UTC] Performing line search
[2021-12-20 17:03:27.548164 UTC] Updating baseline
[2021-12-20 17:03:28.149549 UTC] Computing logging information
------------------------------------
| Iteration            | 62        |
| ExpectedImprovement  | 0.019808  |
| ActualImprovement    | 0.015541  |
| ImprovementRatio     | 0.78459   |
| MeanKL               | 0.0090879 |
| Entropy              | 0.83941   |
| Perplexity           | 2.315     |
| AveragePolicyStd     | 0.56016   |
| AveragePolicyStd[0]  | 0.56016   |
| AverageReturn        | -157.38   |
| MinReturn            | -389.71   |
| MaxReturn            | -0.637    |
| StdReturn            | 98.758    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3136      |
| TotalNSamples        | 6.272e+05 |
| ExplainedVariance    | 0.97502   |
------------------------------------
[2021-12-20 17:03:28.231767 UTC] Saving snapshot
[2021-12-20 17:03:28.247974 UTC] Starting iteration 63
[2021-12-20 17:03:28.249312 UTC] Start collecting samples
[2021-12-20 17:03:30.332459 UTC] Computing input variables for policy optimization
[2021-12-20 17:03:30.431403 UTC] Performing policy update
[2021-12-20 17:03:30.435448 UTC] Computing gradient in Euclidean space
[2021-12-20 17:03:30.513637 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:03:31.176023 UTC] Performing line search
[2021-12-20 17:03:31.212309 UTC] Updating baseline
[2021-12-20 17:03:32.020013 UTC] Computing logging information
------------------------------------
| Iteration            | 63        |
| ExpectedImprovement  | 0.015762  |
| ActualImprovement    | 0.013072  |
| ImprovementRatio     | 0.82935   |
| MeanKL               | 0.0075807 |
| Entropy              | 0.83536   |
| Perplexity           | 2.3056    |
| AveragePolicyStd     | 0.5579    |
| AveragePolicyStd[0]  | 0.5579    |
| AverageReturn        | -126.91   |
| MinReturn            | -389.71   |
| MaxReturn            | -0.60003  |
| StdReturn            | 85.254    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3200      |
| TotalNSamples        | 6.4e+05   |
| ExplainedVariance    | 0.97697   |
------------------------------------
[2021-12-20 17:03:32.147256 UTC] Saving snapshot
[2021-12-20 17:03:32.155015 UTC] Starting iteration 64
[2021-12-20 17:03:32.155408 UTC] Start collecting samples
[2021-12-20 17:03:33.976579 UTC] Computing input variables for policy optimization
[2021-12-20 17:03:34.040519 UTC] Performing policy update
[2021-12-20 17:03:34.044989 UTC] Computing gradient in Euclidean space
[2021-12-20 17:03:34.097908 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:03:34.694177 UTC] Performing line search
[2021-12-20 17:03:34.765964 UTC] Updating baseline
[2021-12-20 17:03:35.445106 UTC] Computing logging information
------------------------------------
| Iteration            | 64        |
| ExpectedImprovement  | 0.0099962 |
| ActualImprovement    | 0.010746  |
| ImprovementRatio     | 1.075     |
| MeanKL               | 0.006827  |
| Entropy              | 0.83109   |
| Perplexity           | 2.2958    |
| AveragePolicyStd     | 0.55552   |
| AveragePolicyStd[0]  | 0.55552   |
| AverageReturn        | -141.73   |
| MinReturn            | -334.03   |
| MaxReturn            | -0.60003  |
| StdReturn            | 83.662    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3248      |
| TotalNSamples        | 6.496e+05 |
| ExplainedVariance    | 0.99184   |
------------------------------------
[2021-12-20 17:03:35.540764 UTC] Saving snapshot
[2021-12-20 17:03:35.553402 UTC] Starting iteration 65
[2021-12-20 17:03:35.554008 UTC] Start collecting samples
[2021-12-20 17:03:37.925759 UTC] Computing input variables for policy optimization
[2021-12-20 17:03:38.009125 UTC] Performing policy update
[2021-12-20 17:03:38.013739 UTC] Computing gradient in Euclidean space
[2021-12-20 17:03:38.081329 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:03:38.801572 UTC] Performing line search
[2021-12-20 17:03:38.858466 UTC] Updating baseline
[2021-12-20 17:03:39.596436 UTC] Computing logging information
------------------------------------
| Iteration            | 65        |
| ExpectedImprovement  | 0.011372  |
| ActualImprovement    | 0.0084987 |
| ImprovementRatio     | 0.74736   |
| MeanKL               | 0.0069053 |
| Entropy              | 0.81797   |
| Perplexity           | 2.2659    |
| AveragePolicyStd     | 0.54828   |
| AveragePolicyStd[0]  | 0.54828   |
| AverageReturn        | -154.59   |
| MinReturn            | -376.82   |
| MaxReturn            | -0.59354  |
| StdReturn            | 87.96     |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3296      |
| TotalNSamples        | 6.592e+05 |
| ExplainedVariance    | 0.99352   |
------------------------------------
[2021-12-20 17:03:39.715989 UTC] Saving snapshot
[2021-12-20 17:03:39.727738 UTC] Starting iteration 66
[2021-12-20 17:03:39.731128 UTC] Start collecting samples
[2021-12-20 17:03:41.913526 UTC] Computing input variables for policy optimization
[2021-12-20 17:03:41.980280 UTC] Performing policy update
[2021-12-20 17:03:41.987343 UTC] Computing gradient in Euclidean space
[2021-12-20 17:03:42.047638 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:03:42.746790 UTC] Performing line search
[2021-12-20 17:03:42.827891 UTC] Updating baseline
[2021-12-20 17:03:43.655006 UTC] Computing logging information
------------------------------------
| Iteration            | 66        |
| ExpectedImprovement  | 0.014719  |
| ActualImprovement    | 0.011952  |
| ImprovementRatio     | 0.81201   |
| MeanKL               | 0.0071919 |
| Entropy              | 0.81059   |
| Perplexity           | 2.2492    |
| AveragePolicyStd     | 0.54425   |
| AveragePolicyStd[0]  | 0.54425   |
| AverageReturn        | -150.73   |
| MinReturn            | -376.82   |
| MaxReturn            | -0.53641  |
| StdReturn            | 93.861    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3344      |
| TotalNSamples        | 6.688e+05 |
| ExplainedVariance    | 0.98276   |
------------------------------------
[2021-12-20 17:03:43.785225 UTC] Saving snapshot
[2021-12-20 17:03:43.794388 UTC] Starting iteration 67
[2021-12-20 17:03:43.794701 UTC] Start collecting samples
[2021-12-20 17:03:46.005798 UTC] Computing input variables for policy optimization
[2021-12-20 17:03:46.092131 UTC] Performing policy update
[2021-12-20 17:03:46.094026 UTC] Computing gradient in Euclidean space
[2021-12-20 17:03:46.142297 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:03:46.794219 UTC] Performing line search
[2021-12-20 17:03:46.889720 UTC] Updating baseline
[2021-12-20 17:03:47.676067 UTC] Computing logging information
------------------------------------
| Iteration            | 67        |
| ExpectedImprovement  | 0.010584  |
| ActualImprovement    | 0.011053  |
| ImprovementRatio     | 1.0443    |
| MeanKL               | 0.007312  |
| Entropy              | 0.77459   |
| Perplexity           | 2.1697    |
| AveragePolicyStd     | 0.52501   |
| AveragePolicyStd[0]  | 0.52501   |
| AverageReturn        | -157.13   |
| MinReturn            | -369.13   |
| MaxReturn            | -0.53641  |
| StdReturn            | 89.23     |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3392      |
| TotalNSamples        | 6.784e+05 |
| ExplainedVariance    | 0.97982   |
------------------------------------
[2021-12-20 17:03:47.779743 UTC] Saving snapshot
[2021-12-20 17:03:47.785440 UTC] Starting iteration 68
[2021-12-20 17:03:47.785694 UTC] Start collecting samples
[2021-12-20 17:03:49.847985 UTC] Computing input variables for policy optimization
[2021-12-20 17:03:49.925097 UTC] Performing policy update
[2021-12-20 17:03:49.926338 UTC] Computing gradient in Euclidean space
[2021-12-20 17:03:49.983850 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:03:50.595989 UTC] Performing line search
[2021-12-20 17:03:50.675588 UTC] Updating baseline
[2021-12-20 17:03:51.416170 UTC] Computing logging information
------------------------------------
| Iteration            | 68        |
| ExpectedImprovement  | 0.019352  |
| ActualImprovement    | 0.017174  |
| ImprovementRatio     | 0.88749   |
| MeanKL               | 0.0069598 |
| Entropy              | 0.77881   |
| Perplexity           | 2.1789    |
| AveragePolicyStd     | 0.52722   |
| AveragePolicyStd[0]  | 0.52722   |
| AverageReturn        | -162.32   |
| MinReturn            | -398.74   |
| MaxReturn            | -0.54778  |
| StdReturn            | 96.678    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3440      |
| TotalNSamples        | 6.88e+05  |
| ExplainedVariance    | 0.99065   |
------------------------------------
[2021-12-20 17:03:51.507175 UTC] Saving snapshot
[2021-12-20 17:03:51.517358 UTC] Starting iteration 69
[2021-12-20 17:03:51.517758 UTC] Start collecting samples
[2021-12-20 17:03:53.457616 UTC] Computing input variables for policy optimization
[2021-12-20 17:03:53.514046 UTC] Performing policy update
[2021-12-20 17:03:53.521573 UTC] Computing gradient in Euclidean space
[2021-12-20 17:03:53.575152 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:03:54.098859 UTC] Performing line search
[2021-12-20 17:03:54.155540 UTC] Updating baseline
[2021-12-20 17:03:54.830144 UTC] Computing logging information
------------------------------------
| Iteration            | 69        |
| ExpectedImprovement  | 0.013462  |
| ActualImprovement    | 0.015678  |
| ImprovementRatio     | 1.1646    |
| MeanKL               | 0.0078007 |
| Entropy              | 0.77152   |
| Perplexity           | 2.1631    |
| AveragePolicyStd     | 0.5234    |
| AveragePolicyStd[0]  | 0.5234    |
| AverageReturn        | -142.25   |
| MinReturn            | -398.74   |
| MaxReturn            | -0.54778  |
| StdReturn            | 90.737    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3488      |
| TotalNSamples        | 6.976e+05 |
| ExplainedVariance    | 0.96014   |
------------------------------------
[2021-12-20 17:03:54.937906 UTC] Saving snapshot
[2021-12-20 17:03:54.945195 UTC] Starting iteration 70
[2021-12-20 17:03:54.945615 UTC] Start collecting samples
[2021-12-20 17:03:56.866155 UTC] Computing input variables for policy optimization
[2021-12-20 17:03:56.947222 UTC] Performing policy update
[2021-12-20 17:03:56.951038 UTC] Computing gradient in Euclidean space
[2021-12-20 17:03:57.005624 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:03:57.738260 UTC] Performing line search
[2021-12-20 17:03:57.828445 UTC] Updating baseline
[2021-12-20 17:03:58.549985 UTC] Computing logging information
------------------------------------
| Iteration            | 70        |
| ExpectedImprovement  | 0.018392  |
| ActualImprovement    | 0.01896   |
| ImprovementRatio     | 1.0308    |
| MeanKL               | 0.0066862 |
| Entropy              | 0.73934   |
| Perplexity           | 2.0945    |
| AveragePolicyStd     | 0.50682   |
| AveragePolicyStd[0]  | 0.50682   |
| AverageReturn        | -146.95   |
| MinReturn            | -404.1    |
| MaxReturn            | -0.5806   |
| StdReturn            | 93.612    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3536      |
| TotalNSamples        | 7.072e+05 |
| ExplainedVariance    | 0.98474   |
------------------------------------
[2021-12-20 17:03:58.653180 UTC] Saving snapshot
[2021-12-20 17:03:58.661110 UTC] Starting iteration 71
[2021-12-20 17:03:58.661707 UTC] Start collecting samples
[2021-12-20 17:04:00.665889 UTC] Computing input variables for policy optimization
[2021-12-20 17:04:00.737296 UTC] Performing policy update
[2021-12-20 17:04:00.740372 UTC] Computing gradient in Euclidean space
[2021-12-20 17:04:00.812809 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:04:01.404212 UTC] Performing line search
[2021-12-20 17:04:01.449850 UTC] Updating baseline
[2021-12-20 17:04:02.260764 UTC] Computing logging information
------------------------------------
| Iteration            | 71        |
| ExpectedImprovement  | 0.017778  |
| ActualImprovement    | 0.015455  |
| ImprovementRatio     | 0.86931   |
| MeanKL               | 0.0098719 |
| Entropy              | 0.74092   |
| Perplexity           | 2.0979    |
| AveragePolicyStd     | 0.50762   |
| AveragePolicyStd[0]  | 0.50762   |
| AverageReturn        | -150.1    |
| MinReturn            | -404.1    |
| MaxReturn            | -0.5806   |
| StdReturn            | 96.14     |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3600      |
| TotalNSamples        | 7.2e+05   |
| ExplainedVariance    | 0.98802   |
------------------------------------
[2021-12-20 17:04:02.372671 UTC] Saving snapshot
[2021-12-20 17:04:02.388910 UTC] Starting iteration 72
[2021-12-20 17:04:02.389273 UTC] Start collecting samples
[2021-12-20 17:04:04.730213 UTC] Computing input variables for policy optimization
[2021-12-20 17:04:04.798113 UTC] Performing policy update
[2021-12-20 17:04:04.799286 UTC] Computing gradient in Euclidean space
[2021-12-20 17:04:04.850862 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:04:05.533899 UTC] Performing line search
[2021-12-20 17:04:05.591556 UTC] Updating baseline
[2021-12-20 17:04:06.391704 UTC] Computing logging information
------------------------------------
| Iteration            | 72        |
| ExpectedImprovement  | 0.017948  |
| ActualImprovement    | 0.016436  |
| ImprovementRatio     | 0.91576   |
| MeanKL               | 0.0067903 |
| Entropy              | 0.73239   |
| Perplexity           | 2.08      |
| AveragePolicyStd     | 0.50331   |
| AveragePolicyStd[0]  | 0.50331   |
| AverageReturn        | -151.36   |
| MinReturn            | -379.28   |
| MaxReturn            | -0.50546  |
| StdReturn            | 88.067    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3648      |
| TotalNSamples        | 7.296e+05 |
| ExplainedVariance    | 0.97379   |
------------------------------------
[2021-12-20 17:04:06.502829 UTC] Saving snapshot
[2021-12-20 17:04:06.525821 UTC] Starting iteration 73
[2021-12-20 17:04:06.526186 UTC] Start collecting samples
[2021-12-20 17:04:08.828691 UTC] Computing input variables for policy optimization
[2021-12-20 17:04:08.892347 UTC] Performing policy update
[2021-12-20 17:04:08.900171 UTC] Computing gradient in Euclidean space
[2021-12-20 17:04:08.965791 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:04:09.523693 UTC] Performing line search
[2021-12-20 17:04:09.591770 UTC] Updating baseline
[2021-12-20 17:04:10.233288 UTC] Computing logging information
------------------------------------
| Iteration            | 73        |
| ExpectedImprovement  | 0.01138   |
| ActualImprovement    | 0.011013  |
| ImprovementRatio     | 0.96773   |
| MeanKL               | 0.0068847 |
| Entropy              | 0.72054   |
| Perplexity           | 2.0555    |
| AveragePolicyStd     | 0.49738   |
| AveragePolicyStd[0]  | 0.49738   |
| AverageReturn        | -148.39   |
| MinReturn            | -379.28   |
| MaxReturn            | -0.44382  |
| StdReturn            | 89.662    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3696      |
| TotalNSamples        | 7.392e+05 |
| ExplainedVariance    | 0.97948   |
------------------------------------
[2021-12-20 17:04:10.313852 UTC] Saving snapshot
[2021-12-20 17:04:10.321328 UTC] Starting iteration 74
[2021-12-20 17:04:10.321591 UTC] Start collecting samples
[2021-12-20 17:04:12.022976 UTC] Computing input variables for policy optimization
[2021-12-20 17:04:12.105628 UTC] Performing policy update
[2021-12-20 17:04:12.107010 UTC] Computing gradient in Euclidean space
[2021-12-20 17:04:12.163285 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:04:12.723161 UTC] Performing line search
[2021-12-20 17:04:12.751014 UTC] Updating baseline
[2021-12-20 17:04:13.429931 UTC] Computing logging information
------------------------------------
| Iteration            | 74        |
| ExpectedImprovement  | 0.023376  |
| ActualImprovement    | 0.025311  |
| ImprovementRatio     | 1.0828    |
| MeanKL               | 0.0099265 |
| Entropy              | 0.70849   |
| Perplexity           | 2.0309    |
| AveragePolicyStd     | 0.49142   |
| AveragePolicyStd[0]  | 0.49142   |
| AverageReturn        | -140.08   |
| MinReturn            | -413.79   |
| MaxReturn            | -0.44382  |
| StdReturn            | 93.441    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3744      |
| TotalNSamples        | 7.488e+05 |
| ExplainedVariance    | 0.9924    |
------------------------------------
[2021-12-20 17:04:13.514821 UTC] Saving snapshot
[2021-12-20 17:04:13.523206 UTC] Starting iteration 75
[2021-12-20 17:04:13.523803 UTC] Start collecting samples
[2021-12-20 17:04:15.442750 UTC] Computing input variables for policy optimization
[2021-12-20 17:04:15.506097 UTC] Performing policy update
[2021-12-20 17:04:15.507903 UTC] Computing gradient in Euclidean space
[2021-12-20 17:04:15.564353 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:04:16.088089 UTC] Performing line search
[2021-12-20 17:04:16.119410 UTC] Updating baseline
[2021-12-20 17:04:16.742865 UTC] Computing logging information
------------------------------------
| Iteration            | 75        |
| ExpectedImprovement  | 0.021167  |
| ActualImprovement    | 0.027576  |
| ImprovementRatio     | 1.3028    |
| MeanKL               | 0.0093214 |
| Entropy              | 0.7195    |
| Perplexity           | 2.0534    |
| AveragePolicyStd     | 0.49686   |
| AveragePolicyStd[0]  | 0.49686   |
| AverageReturn        | -146.66   |
| MinReturn            | -413.79   |
| MaxReturn            | -0.53042  |
| StdReturn            | 93.241    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3792      |
| TotalNSamples        | 7.584e+05 |
| ExplainedVariance    | 0.98332   |
------------------------------------
[2021-12-20 17:04:16.826298 UTC] Saving snapshot
[2021-12-20 17:04:16.836855 UTC] Starting iteration 76
[2021-12-20 17:04:16.837117 UTC] Start collecting samples
[2021-12-20 17:04:18.690602 UTC] Computing input variables for policy optimization
[2021-12-20 17:04:18.750494 UTC] Performing policy update
[2021-12-20 17:04:18.751665 UTC] Computing gradient in Euclidean space
[2021-12-20 17:04:18.807253 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:04:19.438467 UTC] Performing line search
[2021-12-20 17:04:19.537746 UTC] Updating baseline
[2021-12-20 17:04:20.190290 UTC] Computing logging information
------------------------------------
| Iteration            | 76        |
| ExpectedImprovement  | 0.014132  |
| ActualImprovement    | 0.013373  |
| ImprovementRatio     | 0.94632   |
| MeanKL               | 0.0071764 |
| Entropy              | 0.72276   |
| Perplexity           | 2.0601    |
| AveragePolicyStd     | 0.49849   |
| AveragePolicyStd[0]  | 0.49849   |
| AverageReturn        | -145.49   |
| MinReturn            | -353.33   |
| MaxReturn            | -0.50197  |
| StdReturn            | 84.173    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3840      |
| TotalNSamples        | 7.68e+05  |
| ExplainedVariance    | 0.98777   |
------------------------------------
[2021-12-20 17:04:20.279091 UTC] Saving snapshot
[2021-12-20 17:04:20.289912 UTC] Starting iteration 77
[2021-12-20 17:04:20.290202 UTC] Start collecting samples
[2021-12-20 17:04:22.155217 UTC] Computing input variables for policy optimization
[2021-12-20 17:04:22.241938 UTC] Performing policy update
[2021-12-20 17:04:22.242722 UTC] Computing gradient in Euclidean space
[2021-12-20 17:04:22.344700 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:04:23.538742 UTC] Performing line search
[2021-12-20 17:04:23.629538 UTC] Updating baseline
[2021-12-20 17:04:24.422040 UTC] Computing logging information
------------------------------------
| Iteration            | 77        |
| ExpectedImprovement  | 0.013369  |
| ActualImprovement    | 0.013226  |
| ImprovementRatio     | 0.98937   |
| MeanKL               | 0.0067516 |
| Entropy              | 0.71788   |
| Perplexity           | 2.0501    |
| AveragePolicyStd     | 0.49606   |
| AveragePolicyStd[0]  | 0.49606   |
| AverageReturn        | -144.02   |
| MinReturn            | -347.49   |
| MaxReturn            | -0.49071  |
| StdReturn            | 76.572    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3888      |
| TotalNSamples        | 7.776e+05 |
| ExplainedVariance    | 0.99378   |
------------------------------------
[2021-12-20 17:04:24.581455 UTC] Saving snapshot
[2021-12-20 17:04:24.594122 UTC] Starting iteration 78
[2021-12-20 17:04:24.594550 UTC] Start collecting samples
[2021-12-20 17:04:28.021753 UTC] Computing input variables for policy optimization
[2021-12-20 17:04:28.093310 UTC] Performing policy update
[2021-12-20 17:04:28.100242 UTC] Computing gradient in Euclidean space
[2021-12-20 17:04:28.194975 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:04:29.175966 UTC] Performing line search
[2021-12-20 17:04:29.254550 UTC] Updating baseline
[2021-12-20 17:04:30.300877 UTC] Computing logging information
------------------------------------
| Iteration            | 78        |
| ExpectedImprovement  | 0.013813  |
| ActualImprovement    | 0.014392  |
| ImprovementRatio     | 1.0419    |
| MeanKL               | 0.0065949 |
| Entropy              | 0.71131   |
| Perplexity           | 2.0367    |
| AveragePolicyStd     | 0.49281   |
| AveragePolicyStd[0]  | 0.49281   |
| AverageReturn        | -148.64   |
| MinReturn            | -347.49   |
| MaxReturn            | -0.49071  |
| StdReturn            | 85.884    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 3936      |
| TotalNSamples        | 7.872e+05 |
| ExplainedVariance    | 0.98821   |
------------------------------------
[2021-12-20 17:04:30.460058 UTC] Saving snapshot
[2021-12-20 17:04:30.477348 UTC] Starting iteration 79
[2021-12-20 17:04:30.478258 UTC] Start collecting samples
[2021-12-20 17:04:32.680706 UTC] Computing input variables for policy optimization
[2021-12-20 17:04:32.802151 UTC] Performing policy update
[2021-12-20 17:04:32.805848 UTC] Computing gradient in Euclidean space
[2021-12-20 17:04:32.890104 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:04:33.666006 UTC] Performing line search
[2021-12-20 17:04:33.765949 UTC] Updating baseline
[2021-12-20 17:04:34.798365 UTC] Computing logging information
------------------------------------
| Iteration            | 79        |
| ExpectedImprovement  | 0.012446  |
| ActualImprovement    | 0.011642  |
| ImprovementRatio     | 0.93537   |
| MeanKL               | 0.0065808 |
| Entropy              | 0.69461   |
| Perplexity           | 2.0029    |
| AveragePolicyStd     | 0.48465   |
| AveragePolicyStd[0]  | 0.48465   |
| AverageReturn        | -142.83   |
| MinReturn            | -368.76   |
| MaxReturn            | -0.5598   |
| StdReturn            | 94.613    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4000      |
| TotalNSamples        | 8e+05     |
| ExplainedVariance    | 0.99063   |
------------------------------------
[2021-12-20 17:04:34.898093 UTC] Saving snapshot
[2021-12-20 17:04:34.916167 UTC] Starting iteration 80
[2021-12-20 17:04:34.920183 UTC] Start collecting samples
[2021-12-20 17:04:37.319314 UTC] Computing input variables for policy optimization
[2021-12-20 17:04:37.440047 UTC] Performing policy update
[2021-12-20 17:04:37.443021 UTC] Computing gradient in Euclidean space
[2021-12-20 17:04:37.538362 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:04:38.429320 UTC] Performing line search
[2021-12-20 17:04:38.551168 UTC] Updating baseline
[2021-12-20 17:04:39.433542 UTC] Computing logging information
------------------------------------
| Iteration            | 80        |
| ExpectedImprovement  | 0.011407  |
| ActualImprovement    | 0.011528  |
| ImprovementRatio     | 1.0106    |
| MeanKL               | 0.007583  |
| Entropy              | 0.71877   |
| Perplexity           | 2.0519    |
| AveragePolicyStd     | 0.4965    |
| AveragePolicyStd[0]  | 0.4965    |
| AverageReturn        | -157.08   |
| MinReturn            | -411.36   |
| MaxReturn            | -0.5598   |
| StdReturn            | 101.62    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4048      |
| TotalNSamples        | 8.096e+05 |
| ExplainedVariance    | 0.98644   |
------------------------------------
[2021-12-20 17:04:39.579788 UTC] Saving snapshot
[2021-12-20 17:04:39.586220 UTC] Starting iteration 81
[2021-12-20 17:04:39.586541 UTC] Start collecting samples
[2021-12-20 17:04:42.747901 UTC] Computing input variables for policy optimization
[2021-12-20 17:04:42.867635 UTC] Performing policy update
[2021-12-20 17:04:42.871914 UTC] Computing gradient in Euclidean space
[2021-12-20 17:04:42.942701 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:04:43.682178 UTC] Performing line search
[2021-12-20 17:04:43.748732 UTC] Updating baseline
[2021-12-20 17:04:44.945856 UTC] Computing logging information
------------------------------------
| Iteration            | 81        |
| ExpectedImprovement  | 0.012384  |
| ActualImprovement    | 0.011005  |
| ImprovementRatio     | 0.88859   |
| MeanKL               | 0.0067211 |
| Entropy              | 0.72058   |
| Perplexity           | 2.0556    |
| AveragePolicyStd     | 0.4974    |
| AveragePolicyStd[0]  | 0.4974    |
| AverageReturn        | -157.94   |
| MinReturn            | -411.36   |
| MaxReturn            | -0.57114  |
| StdReturn            | 98.471    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4096      |
| TotalNSamples        | 8.192e+05 |
| ExplainedVariance    | 0.98434   |
------------------------------------
[2021-12-20 17:04:45.112197 UTC] Saving snapshot
[2021-12-20 17:04:45.119914 UTC] Starting iteration 82
[2021-12-20 17:04:45.133350 UTC] Start collecting samples
[2021-12-20 17:04:51.334898 UTC] Computing input variables for policy optimization
[2021-12-20 17:04:51.477517 UTC] Performing policy update
[2021-12-20 17:04:51.482436 UTC] Computing gradient in Euclidean space
[2021-12-20 17:04:51.572550 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:04:52.628146 UTC] Performing line search
[2021-12-20 17:04:52.696618 UTC] Updating baseline
[2021-12-20 17:04:53.541105 UTC] Computing logging information
------------------------------------
| Iteration            | 82        |
| ExpectedImprovement  | 0.017772  |
| ActualImprovement    | 0.018546  |
| ImprovementRatio     | 1.0436    |
| MeanKL               | 0.0090027 |
| Entropy              | 0.70769   |
| Perplexity           | 2.0293    |
| AveragePolicyStd     | 0.49103   |
| AveragePolicyStd[0]  | 0.49103   |
| AverageReturn        | -138.12   |
| MinReturn            | -357.53   |
| MaxReturn            | -0.57114  |
| StdReturn            | 87.59     |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4144      |
| TotalNSamples        | 8.288e+05 |
| ExplainedVariance    | 0.98838   |
------------------------------------
[2021-12-20 17:04:53.630703 UTC] Saving snapshot
[2021-12-20 17:04:53.634690 UTC] Starting iteration 83
[2021-12-20 17:04:53.635307 UTC] Start collecting samples
[2021-12-20 17:05:01.024174 UTC] Computing input variables for policy optimization
[2021-12-20 17:05:01.111881 UTC] Performing policy update
[2021-12-20 17:05:01.118761 UTC] Computing gradient in Euclidean space
[2021-12-20 17:05:01.205778 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:05:02.343586 UTC] Performing line search
[2021-12-20 17:05:02.388366 UTC] Updating baseline
[2021-12-20 17:05:03.911373 UTC] Computing logging information
------------------------------------
| Iteration            | 83        |
| ExpectedImprovement  | 0.013818  |
| ActualImprovement    | 0.0097443 |
| ImprovementRatio     | 0.70521   |
| MeanKL               | 0.0098077 |
| Entropy              | 0.71021   |
| Perplexity           | 2.0344    |
| AveragePolicyStd     | 0.49227   |
| AveragePolicyStd[0]  | 0.49227   |
| AverageReturn        | -137.43   |
| MinReturn            | -357.53   |
| MaxReturn            | -0.5317   |
| StdReturn            | 78.623    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4192      |
| TotalNSamples        | 8.384e+05 |
| ExplainedVariance    | 0.98588   |
------------------------------------
[2021-12-20 17:05:04.017559 UTC] Saving snapshot
[2021-12-20 17:05:04.028623 UTC] Starting iteration 84
[2021-12-20 17:05:04.040283 UTC] Start collecting samples
[2021-12-20 17:05:07.259126 UTC] Computing input variables for policy optimization
[2021-12-20 17:05:07.323163 UTC] Performing policy update
[2021-12-20 17:05:07.337709 UTC] Computing gradient in Euclidean space
[2021-12-20 17:05:07.397519 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:05:08.020794 UTC] Performing line search
[2021-12-20 17:05:08.059227 UTC] Updating baseline
[2021-12-20 17:05:09.649477 UTC] Computing logging information
------------------------------------
| Iteration            | 84        |
| ExpectedImprovement  | 0.014957  |
| ActualImprovement    | 0.0081484 |
| ImprovementRatio     | 0.54479   |
| MeanKL               | 0.0092494 |
| Entropy              | 0.70828   |
| Perplexity           | 2.0305    |
| AveragePolicyStd     | 0.49132   |
| AveragePolicyStd[0]  | 0.49132   |
| AverageReturn        | -151.5    |
| MinReturn            | -366.22   |
| MaxReturn            | -0.5317   |
| StdReturn            | 80.758    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4240      |
| TotalNSamples        | 8.48e+05  |
| ExplainedVariance    | 0.9749    |
------------------------------------
[2021-12-20 17:05:09.775322 UTC] Saving snapshot
[2021-12-20 17:05:09.792044 UTC] Starting iteration 85
[2021-12-20 17:05:09.800673 UTC] Start collecting samples
[2021-12-20 17:05:16.021342 UTC] Computing input variables for policy optimization
[2021-12-20 17:05:16.508956 UTC] Performing policy update
[2021-12-20 17:05:16.520731 UTC] Computing gradient in Euclidean space
[2021-12-20 17:05:16.624136 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:05:17.776656 UTC] Performing line search
[2021-12-20 17:05:17.844345 UTC] Updating baseline
[2021-12-20 17:05:18.714760 UTC] Computing logging information
------------------------------------
| Iteration            | 85        |
| ExpectedImprovement  | 0.01633   |
| ActualImprovement    | 0.014808  |
| ImprovementRatio     | 0.90676   |
| MeanKL               | 0.0064807 |
| Entropy              | 0.68447   |
| Perplexity           | 1.9827    |
| AveragePolicyStd     | 0.47976   |
| AveragePolicyStd[0]  | 0.47976   |
| AverageReturn        | -155.75   |
| MinReturn            | -366.22   |
| MaxReturn            | -0.75731  |
| StdReturn            | 86.173    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4288      |
| TotalNSamples        | 8.576e+05 |
| ExplainedVariance    | 0.98867   |
------------------------------------
[2021-12-20 17:05:18.821681 UTC] Saving snapshot
[2021-12-20 17:05:18.828837 UTC] Starting iteration 86
[2021-12-20 17:05:18.829116 UTC] Start collecting samples
[2021-12-20 17:05:21.565095 UTC] Computing input variables for policy optimization
[2021-12-20 17:05:21.636505 UTC] Performing policy update
[2021-12-20 17:05:21.637256 UTC] Computing gradient in Euclidean space
[2021-12-20 17:05:21.720215 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:05:22.436595 UTC] Performing line search
[2021-12-20 17:05:22.670156 UTC] Updating baseline
[2021-12-20 17:05:23.531678 UTC] Computing logging information
------------------------------------
| Iteration            | 86        |
| ExpectedImprovement  | 0.03982   |
| ActualImprovement    | 0.015715  |
| ImprovementRatio     | 0.39466   |
| MeanKL               | 0.0097497 |
| Entropy              | 0.6716    |
| Perplexity           | 1.9574    |
| AveragePolicyStd     | 0.47363   |
| AveragePolicyStd[0]  | 0.47363   |
| AverageReturn        | -150.19   |
| MinReturn            | -396.68   |
| MaxReturn            | -0.54553  |
| StdReturn            | 95.644    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4336      |
| TotalNSamples        | 8.672e+05 |
| ExplainedVariance    | 0.98821   |
------------------------------------
[2021-12-20 17:05:23.631105 UTC] Saving snapshot
[2021-12-20 17:05:23.640353 UTC] Starting iteration 87
[2021-12-20 17:05:23.641001 UTC] Start collecting samples
[2021-12-20 17:05:27.778637 UTC] Computing input variables for policy optimization
[2021-12-20 17:05:28.371104 UTC] Performing policy update
[2021-12-20 17:05:28.381984 UTC] Computing gradient in Euclidean space
[2021-12-20 17:05:28.522530 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:05:29.727118 UTC] Performing line search
[2021-12-20 17:05:29.793622 UTC] Updating baseline
[2021-12-20 17:05:31.649659 UTC] Computing logging information
------------------------------------
| Iteration            | 87        |
| ExpectedImprovement  | 0.022547  |
| ActualImprovement    | 0.030517  |
| ImprovementRatio     | 1.3535    |
| MeanKL               | 0.0097106 |
| Entropy              | 0.65452   |
| Perplexity           | 1.9242    |
| AveragePolicyStd     | 0.46561   |
| AveragePolicyStd[0]  | 0.46561   |
| AverageReturn        | -146.07   |
| MinReturn            | -396.68   |
| MaxReturn            | -0.537    |
| StdReturn            | 89.217    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4400      |
| TotalNSamples        | 8.8e+05   |
| ExplainedVariance    | 0.98999   |
------------------------------------
[2021-12-20 17:05:31.750500 UTC] Saving snapshot
[2021-12-20 17:05:31.766177 UTC] Starting iteration 88
[2021-12-20 17:05:31.766771 UTC] Start collecting samples
[2021-12-20 17:05:34.238030 UTC] Computing input variables for policy optimization
[2021-12-20 17:05:34.302600 UTC] Performing policy update
[2021-12-20 17:05:34.303405 UTC] Computing gradient in Euclidean space
[2021-12-20 17:05:34.372723 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:05:35.024958 UTC] Performing line search
[2021-12-20 17:05:35.081359 UTC] Updating baseline
[2021-12-20 17:05:35.824847 UTC] Computing logging information
------------------------------------
| Iteration            | 88        |
| ExpectedImprovement  | 0.013054  |
| ActualImprovement    | 0.010849  |
| ImprovementRatio     | 0.83103   |
| MeanKL               | 0.0069226 |
| Entropy              | 0.65939   |
| Perplexity           | 1.9336    |
| AveragePolicyStd     | 0.46788   |
| AveragePolicyStd[0]  | 0.46788   |
| AverageReturn        | -139.53   |
| MinReturn            | -366.55   |
| MaxReturn            | -0.537    |
| StdReturn            | 86.178    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4448      |
| TotalNSamples        | 8.896e+05 |
| ExplainedVariance    | 0.97587   |
------------------------------------
[2021-12-20 17:05:35.990572 UTC] Saving snapshot
[2021-12-20 17:05:35.999188 UTC] Starting iteration 89
[2021-12-20 17:05:36.010748 UTC] Start collecting samples
[2021-12-20 17:05:37.972655 UTC] Computing input variables for policy optimization
[2021-12-20 17:05:38.060060 UTC] Performing policy update
[2021-12-20 17:05:38.062937 UTC] Computing gradient in Euclidean space
[2021-12-20 17:05:38.129871 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:05:38.765788 UTC] Performing line search
[2021-12-20 17:05:38.857471 UTC] Updating baseline
[2021-12-20 17:05:39.581158 UTC] Computing logging information
------------------------------------
| Iteration            | 89        |
| ExpectedImprovement  | 0.015712  |
| ActualImprovement    | 0.014339  |
| ImprovementRatio     | 0.91262   |
| MeanKL               | 0.0065485 |
| Entropy              | 0.63526   |
| Perplexity           | 1.8875    |
| AveragePolicyStd     | 0.45672   |
| AveragePolicyStd[0]  | 0.45672   |
| AverageReturn        | -138.53   |
| MinReturn            | -353.23   |
| MaxReturn            | -0.47384  |
| StdReturn            | 85.489    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4496      |
| TotalNSamples        | 8.992e+05 |
| ExplainedVariance    | 0.98313   |
------------------------------------
[2021-12-20 17:05:39.679254 UTC] Saving snapshot
[2021-12-20 17:05:39.691886 UTC] Starting iteration 90
[2021-12-20 17:05:39.692561 UTC] Start collecting samples
[2021-12-20 17:05:41.712052 UTC] Computing input variables for policy optimization
[2021-12-20 17:05:41.790185 UTC] Performing policy update
[2021-12-20 17:05:41.791675 UTC] Computing gradient in Euclidean space
[2021-12-20 17:05:41.845928 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:05:42.422327 UTC] Performing line search
[2021-12-20 17:05:42.481173 UTC] Updating baseline
[2021-12-20 17:05:43.154949 UTC] Computing logging information
------------------------------------
| Iteration            | 90        |
| ExpectedImprovement  | 0.018077  |
| ActualImprovement    | 0.020952  |
| ImprovementRatio     | 1.1591    |
| MeanKL               | 0.0069472 |
| Entropy              | 0.62252   |
| Perplexity           | 1.8636    |
| AveragePolicyStd     | 0.45094   |
| AveragePolicyStd[0]  | 0.45094   |
| AverageReturn        | -149.62   |
| MinReturn            | -353.61   |
| MaxReturn            | -0.40609  |
| StdReturn            | 82.428    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4544      |
| TotalNSamples        | 9.088e+05 |
| ExplainedVariance    | 0.99013   |
------------------------------------
[2021-12-20 17:05:43.289077 UTC] Saving snapshot
[2021-12-20 17:05:43.300309 UTC] Starting iteration 91
[2021-12-20 17:05:43.301447 UTC] Start collecting samples
[2021-12-20 17:05:45.797956 UTC] Computing input variables for policy optimization
[2021-12-20 17:05:46.021275 UTC] Performing policy update
[2021-12-20 17:05:46.022531 UTC] Computing gradient in Euclidean space
[2021-12-20 17:05:46.078688 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:05:47.211247 UTC] Performing line search
[2021-12-20 17:05:47.389047 UTC] Updating baseline
[2021-12-20 17:05:49.054146 UTC] Computing logging information
------------------------------------
| Iteration            | 91        |
| ExpectedImprovement  | 0.009535  |
| ActualImprovement    | 0.0069707 |
| ImprovementRatio     | 0.73107   |
| MeanKL               | 0.0064561 |
| Entropy              | 0.64202   |
| Perplexity           | 1.9003    |
| AveragePolicyStd     | 0.45982   |
| AveragePolicyStd[0]  | 0.45982   |
| AverageReturn        | -140.19   |
| MinReturn            | -353.61   |
| MaxReturn            | -0.40609  |
| StdReturn            | 74.918    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4592      |
| TotalNSamples        | 9.184e+05 |
| ExplainedVariance    | 0.98578   |
------------------------------------
[2021-12-20 17:05:49.218674 UTC] Saving snapshot
[2021-12-20 17:05:49.226445 UTC] Starting iteration 92
[2021-12-20 17:05:49.227845 UTC] Start collecting samples
[2021-12-20 17:05:51.710915 UTC] Computing input variables for policy optimization
[2021-12-20 17:05:51.771854 UTC] Performing policy update
[2021-12-20 17:05:51.774549 UTC] Computing gradient in Euclidean space
[2021-12-20 17:05:51.829613 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:05:52.542451 UTC] Performing line search
[2021-12-20 17:05:52.578383 UTC] Updating baseline
[2021-12-20 17:05:53.259044 UTC] Computing logging information
------------------------------------
| Iteration            | 92        |
| ExpectedImprovement  | 0.014759  |
| ActualImprovement    | 0.012134  |
| ImprovementRatio     | 0.82218   |
| MeanKL               | 0.0092393 |
| Entropy              | 0.63066   |
| Perplexity           | 1.8789    |
| AveragePolicyStd     | 0.45463   |
| AveragePolicyStd[0]  | 0.45463   |
| AverageReturn        | -137.61   |
| MinReturn            | -330.35   |
| MaxReturn            | -0.57196  |
| StdReturn            | 70.493    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4640      |
| TotalNSamples        | 9.28e+05  |
| ExplainedVariance    | 0.96597   |
------------------------------------
[2021-12-20 17:05:53.362132 UTC] Saving snapshot
[2021-12-20 17:05:53.369943 UTC] Starting iteration 93
[2021-12-20 17:05:53.370424 UTC] Start collecting samples
[2021-12-20 17:05:55.670039 UTC] Computing input variables for policy optimization
[2021-12-20 17:05:55.737028 UTC] Performing policy update
[2021-12-20 17:05:55.737836 UTC] Computing gradient in Euclidean space
[2021-12-20 17:05:55.810287 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:05:56.395096 UTC] Performing line search
[2021-12-20 17:05:56.463425 UTC] Updating baseline
[2021-12-20 17:05:57.102314 UTC] Computing logging information
------------------------------------
| Iteration            | 93        |
| ExpectedImprovement  | 0.015103  |
| ActualImprovement    | 0.016672  |
| ImprovementRatio     | 1.1039    |
| MeanKL               | 0.0070789 |
| Entropy              | 0.62005   |
| Perplexity           | 1.859     |
| AveragePolicyStd     | 0.44983   |
| AveragePolicyStd[0]  | 0.44983   |
| AverageReturn        | -153.93   |
| MinReturn            | -384.2    |
| MaxReturn            | -0.40641  |
| StdReturn            | 81.365    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4688      |
| TotalNSamples        | 9.376e+05 |
| ExplainedVariance    | 0.99011   |
------------------------------------
[2021-12-20 17:05:57.203736 UTC] Saving snapshot
[2021-12-20 17:05:57.214720 UTC] Starting iteration 94
[2021-12-20 17:05:57.214980 UTC] Start collecting samples
[2021-12-20 17:05:59.328498 UTC] Computing input variables for policy optimization
[2021-12-20 17:05:59.409692 UTC] Performing policy update
[2021-12-20 17:05:59.410809 UTC] Computing gradient in Euclidean space
[2021-12-20 17:05:59.465434 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:06:00.030477 UTC] Performing line search
[2021-12-20 17:06:00.100791 UTC] Updating baseline
[2021-12-20 17:06:00.927634 UTC] Computing logging information
------------------------------------
| Iteration            | 94        |
| ExpectedImprovement  | 0.013322  |
| ActualImprovement    | 0.012092  |
| ImprovementRatio     | 0.90768   |
| MeanKL               | 0.0078058 |
| Entropy              | 0.62749   |
| Perplexity           | 1.8729    |
| AveragePolicyStd     | 0.45319   |
| AveragePolicyStd[0]  | 0.45319   |
| AverageReturn        | -161.19   |
| MinReturn            | -384.2    |
| MaxReturn            | -0.40641  |
| StdReturn            | 85.512    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4736      |
| TotalNSamples        | 9.472e+05 |
| ExplainedVariance    | 0.98731   |
------------------------------------
[2021-12-20 17:06:01.055140 UTC] Saving snapshot
[2021-12-20 17:06:01.070232 UTC] Starting iteration 95
[2021-12-20 17:06:01.070869 UTC] Start collecting samples
[2021-12-20 17:06:03.167454 UTC] Computing input variables for policy optimization
[2021-12-20 17:06:03.273239 UTC] Performing policy update
[2021-12-20 17:06:03.279786 UTC] Computing gradient in Euclidean space
[2021-12-20 17:06:03.334368 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:06:03.932106 UTC] Performing line search
[2021-12-20 17:06:04.001988 UTC] Updating baseline
[2021-12-20 17:06:04.655934 UTC] Computing logging information
------------------------------------
| Iteration            | 95        |
| ExpectedImprovement  | 0.014034  |
| ActualImprovement    | 0.012811  |
| ImprovementRatio     | 0.91291   |
| MeanKL               | 0.0067627 |
| Entropy              | 0.61925   |
| Perplexity           | 1.8575    |
| AveragePolicyStd     | 0.44947   |
| AveragePolicyStd[0]  | 0.44947   |
| AverageReturn        | -152.97   |
| MinReturn            | -388.85   |
| MaxReturn            | -0.41906  |
| StdReturn            | 85.584    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4800      |
| TotalNSamples        | 9.6e+05   |
| ExplainedVariance    | 0.97619   |
------------------------------------
[2021-12-20 17:06:04.776011 UTC] Saving snapshot
[2021-12-20 17:06:04.781704 UTC] Starting iteration 96
[2021-12-20 17:06:04.782083 UTC] Start collecting samples
[2021-12-20 17:06:06.826281 UTC] Computing input variables for policy optimization
[2021-12-20 17:06:06.910002 UTC] Performing policy update
[2021-12-20 17:06:06.910699 UTC] Computing gradient in Euclidean space
[2021-12-20 17:06:06.973976 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:06:07.579380 UTC] Performing line search
[2021-12-20 17:06:07.664750 UTC] Updating baseline
[2021-12-20 17:06:08.406121 UTC] Computing logging information
------------------------------------
| Iteration            | 96        |
| ExpectedImprovement  | 0.013421  |
| ActualImprovement    | 0.010763  |
| ImprovementRatio     | 0.80195   |
| MeanKL               | 0.0066503 |
| Entropy              | 0.60806   |
| Perplexity           | 1.8369    |
| AveragePolicyStd     | 0.44447   |
| AveragePolicyStd[0]  | 0.44447   |
| AverageReturn        | -158.02   |
| MinReturn            | -388.85   |
| MaxReturn            | -0.41906  |
| StdReturn            | 85.781    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4848      |
| TotalNSamples        | 9.696e+05 |
| ExplainedVariance    | 0.98941   |
------------------------------------
[2021-12-20 17:06:08.581448 UTC] Saving snapshot
[2021-12-20 17:06:08.597218 UTC] Starting iteration 97
[2021-12-20 17:06:08.597598 UTC] Start collecting samples
[2021-12-20 17:06:10.395108 UTC] Computing input variables for policy optimization
[2021-12-20 17:06:10.492277 UTC] Performing policy update
[2021-12-20 17:06:10.495603 UTC] Computing gradient in Euclidean space
[2021-12-20 17:06:10.553753 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:06:11.201147 UTC] Performing line search
[2021-12-20 17:06:11.276143 UTC] Updating baseline
[2021-12-20 17:06:11.974742 UTC] Computing logging information
------------------------------------
| Iteration            | 97        |
| ExpectedImprovement  | 0.015422  |
| ActualImprovement    | 0.011585  |
| ImprovementRatio     | 0.75117   |
| MeanKL               | 0.0067329 |
| Entropy              | 0.60545   |
| Perplexity           | 1.8321    |
| AveragePolicyStd     | 0.44331   |
| AveragePolicyStd[0]  | 0.44331   |
| AverageReturn        | -159.65   |
| MinReturn            | -351.58   |
| MaxReturn            | -0.41917  |
| StdReturn            | 84.864    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4896      |
| TotalNSamples        | 9.792e+05 |
| ExplainedVariance    | 0.98944   |
------------------------------------
[2021-12-20 17:06:12.119293 UTC] Saving snapshot
[2021-12-20 17:06:12.133049 UTC] Starting iteration 98
[2021-12-20 17:06:12.133757 UTC] Start collecting samples
[2021-12-20 17:06:14.118712 UTC] Computing input variables for policy optimization
[2021-12-20 17:06:14.207704 UTC] Performing policy update
[2021-12-20 17:06:14.215018 UTC] Computing gradient in Euclidean space
[2021-12-20 17:06:14.282531 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:06:14.866656 UTC] Performing line search
[2021-12-20 17:06:14.907258 UTC] Updating baseline
[2021-12-20 17:06:15.538613 UTC] Computing logging information
------------------------------------
| Iteration            | 98        |
| ExpectedImprovement  | 0.022111  |
| ActualImprovement    | 0.022199  |
| ImprovementRatio     | 1.004     |
| MeanKL               | 0.0098377 |
| Entropy              | 0.60486   |
| Perplexity           | 1.831     |
| AveragePolicyStd     | 0.44305   |
| AveragePolicyStd[0]  | 0.44305   |
| AverageReturn        | -145.56   |
| MinReturn            | -388.7    |
| MaxReturn            | -0.35844  |
| StdReturn            | 88.343    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4944      |
| TotalNSamples        | 9.888e+05 |
| ExplainedVariance    | 0.9917    |
------------------------------------
[2021-12-20 17:06:15.643121 UTC] Saving snapshot
[2021-12-20 17:06:15.651473 UTC] Starting iteration 99
[2021-12-20 17:06:15.652167 UTC] Start collecting samples
[2021-12-20 17:06:17.549771 UTC] Computing input variables for policy optimization
[2021-12-20 17:06:17.620138 UTC] Performing policy update
[2021-12-20 17:06:17.626234 UTC] Computing gradient in Euclidean space
[2021-12-20 17:06:17.711513 UTC] Computing approximate natural gradient using conjugate gradient algorithm
[2021-12-20 17:06:18.279759 UTC] Performing line search
[2021-12-20 17:06:18.314367 UTC] Updating baseline
[2021-12-20 17:06:18.973591 UTC] Computing logging information
------------------------------------
| Iteration            | 99        |
| ExpectedImprovement  | 0.013901  |
| ActualImprovement    | 0.016351  |
| ImprovementRatio     | 1.1763    |
| MeanKL               | 0.0087147 |
| Entropy              | 0.61012   |
| Perplexity           | 1.8406    |
| AveragePolicyStd     | 0.44538   |
| AveragePolicyStd[0]  | 0.44538   |
| AverageReturn        | -146.07   |
| MinReturn            | -388.7    |
| MaxReturn            | -0.35844  |
| StdReturn            | 86.703    |
| AverageEpisodeLength | 200       |
| MinEpisodeLength     | 200       |
| MaxEpisodeLength     | 200       |
| StdEpisodeLength     | 0         |
| TotalNEpisodes       | 4992      |
| TotalNSamples        | 9.984e+05 |
| ExplainedVariance    | 0.96986   |
------------------------------------
[2021-12-20 17:06:19.113968 UTC] Saving snapshot
